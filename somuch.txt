JAVA基础

JAVA中的几种基本数据类型是什么，各自占用多少字节。
boolean 1b, byte 1b, char 2b, short 2b, int 4b, long 8b, float 4b, double 8b


String类能被继承吗，为什么。
不能，final修饰


String，Stringbuffer，StringBuilder的区别。
不可变类， 可变线程安全，  可变线程不安全


ArrayList和LinkedList有什么区别。
数组实现，扩容时拷贝，查找方便；链表实现，增删方便


讲讲类的实例化顺序，比如父类静态数据，构造函数，字段，子类静态数据，构造函数，字段，当new的时候，他们的执行顺序。
父类静态数据 and 父类静态代码块 > 子类静态数据 and 子类静态代码块 > 父类普通变量、非静态代码块、构造方法 > 子类普通变量、非静态代码块、构造方法


用过哪些Map类，都有什么区别，HashMap是线程安全的吗,并发下使用的Map是什么，他们内部原理分别是什么，比如存储方式，hashcode，扩容，默认容量等。
hashtable             hashmap                 linkedhashmap                treemap
线程安全           线程不安全效率高          线程不安全插入顺序即存储顺序  可以按照指定顺序存储数据，自动排序
 哈希表               哈希表                  hashmap+双向链表记录顺序         红黑树
hashmap/linkedhashmap冲突个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)
存入TreeMap的元素应当实现Comparable接口或者实现Comparator接口，treemap的key不允许null，value允许null；           
Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模
HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取模
HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75
HashMap扩容时是当前容量翻倍即:capacity*2，Hashtable扩容时是容量翻倍+1即:capacity*2+1
HashMap是非线程安全的,只是用于单线程环境下,多线程环境下可以采用concurrent并发包下的concurrentHashMap。HashTable是线程安全的,synchronized
HashMap/linkedhashmap中key和value都允许为null。key为null的键值对永远都放在以table[0]为头结点的链表中。
HashTable在 key、value 遇到null时，会抛出NullPointerException异常
HashMap仅支持Iterator的遍历方式，Hashtable支持Iterator和Enumeration两种遍历方式

				 
JAVA8的ConcurrentHashMap为什么放弃了分段锁，有什么问题吗，如果你来设计，你如何设计。
1.7 ConcurrentHashMap加锁粒度是基于Segment（ReentrantLock）的，包含多个HashEntry。多个线程同时竞争获取同一个segment锁，获取成功的线程更新
map；失败的线程尝试多次获取锁仍未成功，则挂起线程，等待释放锁
1.8 ConcurrentHashMap加锁粒度是基于HashEntry数组，采用Synchronized和CAS，锁粒度变小了。当bucket为空时，使用CAS操作，将Node放入对应的
bucket中当出现hash冲突时，则采用synchronized关键字。链表超过一定长度会转成红黑树。


有没有有顺序的Map实现类，如果有，他们是怎么保证有序的。
linkedhashmap： hashmap+双向链表记录顺序
treemap： 自定义排序，自动维护顺序， 红黑树


抽象类和接口的区别，类可以继承多个类么，接口可以继承多个接口么,类可以实现多个接口么。
接口方法默认public static，接口变量默认public staic final，方法一般是不能实现的；抽象类可以有抽象方法也可以具体方法。
类不可以继承多个类，但是可以实现多个接口，接口可以继承多个接口。


IO模型有哪些，讲讲你理解的nio ，他和bio，aio的区别是啥，谈谈reactor模型。
同步阻塞的BIO，面向流，都是inputstream和outputstream，服务端启动一个severSocket监听特定端口，然后客户端创建指定ip地址和端口的socket去连接
服务器。每有一个客户端连接进来，服务器都要创建一个线程，当有大量客户端连接时，服务器会不堪重负。
同步非阻塞的NIO，面向缓存，从channel读到buffer，从buffer写到channel。事件驱动型，Reactor设计模式，socket会注册感兴趣的事件，少量线程负责
轮询socket，当感兴趣的事件准备好的时候，再创建一个线程去处理。但是具体的IO读写还是阻塞的。
异步非阻塞AIO，Proactor设计模式，不用用户线程亲自读写，OS会把可读的流传入read方法缓冲区，write方法的写入完毕时会通知用户线程。


反射的原理，反射创建类实例的三种方式是什么。
根据类名找到对应的.class文件，通过字节码文件进行一系列操作
Class clazz = Class.forname()；
Class clazz = 实例.getClass()；
Class clazz = 类.class


反射中，Class.forName和ClassLoader区别 。
JVM加载class有三个步骤：加载，链接(检查、准备、解析)，初始化
Class.forName()得到的class对象是已经初始化完毕的。
ClassLoader得到的class对象还没有链接，仅仅加载了而已，不会执行static中的内容,只有在newInstance才会去执行static块。


描述动态代理的几种实现方式，分别说出相应的优缺点。
1. 原生JDK方式。代理类和目标类实现同一接口，代理类持有目标类对象来达到拦截的目的。必须借助接口才能产生代理对象，只有在接口中声明的方法，代理类才能进行拦截。
2. CGLIB，底层使用ASM在内存中动态生成被代理类的子类，即使代理类没有实现任何接口也可以实现动态代理功能。CGLIB简单易用，它的运行速度要远远快于JDK的Proxy动态代理
3. asm
4. javassist


动态代理与cglib实现的区别。
1.原生JDK方式。代理类和目标类实现同一接口，代理类持有目标类对象，来达到拦截的目的。必须借助接口才能产生代理对象，只有在接口中声明的方法，代理类才能进行拦截。
2.CGLIB，底层使用ASM在内存中动态生成被代理类的子类，即使代理类没有实现任何接口也可以实现动态代理功能。CGLIB简单易用，它的运行速度要远远快于JDK的Proxy动态代理


为什么CGlib方式可以对接口实现代理。
CGLIB，底层使用ASM在内存中动态生成被代理类的子类，即使代理类没有实现任何接口也可以实现动态代理功能。CGLIB简单易用，它的运行速度要远远快于JDK的Proxy动态代理


final的用途。
1.final修饰类，类不能被继承
2.final修饰基本类型变量，变量的值不能修改
3.final修饰引用变量，变量不能被指向其它对象
4.final修饰方法，方法不能被重写，但是能被重载


写出三种单例模式实现 。
1.饿汉式
public class Singleton{
	private staic Singleton instance = new Singleton();
	private Singleton(){
		System.out.println("构造方法");
	}
	public Singleton getSingleton(){
		return instance;
	}
}
tips:调用外部类的静态变量和静态方法，不会初始化静态内部类
2.public class Singleton{
	private Singleton(){
		System.out.println("构造方法");
	}
	private static class InnerSingleton{
		private final staic Singleton instance = new Singleton(); 
	}
	public Singleton getSingleton(){
		return InnerSingleton.instance;
	}
}
加同步锁，前后两次判断
3.public class Singleton{
	private volatile Singleton instance = null;
	private Singleton{
		System.out.println("构造方法");
	}
	public Singleton getSingleton(){
		if (instance==null) {
			synchronized(Singleton.class){
				if (instance==null) {
					instance = new Singleton();
				}
			}
		}
		return instance;
	}
}
枚举类
4.public enum Singleton {  
    INSTANCE;  
    public void whateverMethod() {  
    }  
} 


请结合OO设计理念，谈谈访问修饰符public、private、protected、default在应用设计中的作用。
public 对所有人都开放，private 仅对本类成员开放， protected 对本类、子类、本包开放， default 对本类和本包开放


深拷贝和浅拷贝区别。
浅拷贝：源本和副本共享相同的引用类型对象，基本类型是各自一份的，所以修改引用类型会引起源本和副本的同时变化，修改基本类型不会引起同时变化。
深拷贝：源本和副本引用类型和基本类型都是各自一份，所以修改只会影响自己。
Object.clone()实现浅拷贝，若要实现深拷贝，需要将对象引用到的所有类都 implement Cloneable 接口(重写clone方法)，比较麻烦
可以采用序列化的方法实现简单深拷贝，需要将对象引用到的所有类都 implements Serializable 接口(不需要重写方法)
transient 和 static 修饰的属性不能被序列化


error和exception的区别，CheckedException，RuntimeException的区别。
error 表示虚拟机发生了严重错误，必须修改程序。
exception 表示程序可以处理的异常，可以捕获且可能恢复。遇到这类异常，应该尽可能处理异常，使程序恢复运行，而不应该随意终止异常。
CheckedException 受查异常/编译时异常 编写代码的时候必须考虑到的异常，可以 throws 或者 try-catch。
RuntimeException 非受查异常/运行时异常 不需要捕获，一旦抛出 RuntimeException 异常，请修改程序。


请列出5个运行时异常。
空指针异常 NullPointerException 
类找不到异常 ClassNotFoundException 
算数异常 ArithmeticException
数组越界异常 ArrayIndexOutOfBoundsException
类型转换异常 ClassCastException


在自己的代码中，如果创建一个java.lang.String类，这个类是否可以被类加载器加载？为什么？
不可以，因为存在双亲委派模型模型。先交给 bootStrap ClassLoader，若无法加载在交给 extension ClassLoader，若还不能加载则交给 System ClassLoader
通过双亲委托模式传递到引导加载器，而引导加载器在核心 Java API 发现这个名字的类，所以会加载该核心类，并不会加载自己写 java.lang.String类。
这样便可以防止核心API库被随意篡改。
public class String {
    public static void main(String[] args) {
        String str = "my String";
        System.out.println(str);
    }
}
错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为:
   public static void main(String[] args)
否则 JavaFX 应用程序类必须扩展javafx.application.Application

如果我们在 classpath 路径下自定义一个名为 java.lang.MyString 类(该类是胡编的)呢？该类并不存在 java.lang中，经过双亲委托模式，传递到启动类加载器中，
由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过 System 加载器加载该类。
但是这样做是不允许，因为 java.lang 是核心API包，需要访问权限，强制加载将会报出如下异常：
java.lang.SecurityException: Prohibited package name: java.lang


说一说你对java.lang.Object对象中 hashCode和equals方法的理解。在什么场景下需要重新实现这两个方法。
两个对象属性相同应当认为这两个对象是相同的，而不能简单的去比较两个对象的内存地址是否相同。equals 比较的是两个对象的属性，若 equals返回true，
两个对象的hashcode必须相等；若两个对象的 hashcode相等，equals不一定为true。
需要根据对象属性去判断两个对象是否相等的场景需要重写 hashcode 和 equals


在jdk1.5中，引入了泛型，泛型的存在是用来解决什么问题。
泛型的主要目标是实现 java 的类型安全。 泛型可以使编译器知道一个对象的限定类型是什么，从而检查是否有代码错误。
消除了强制类型转换 使得代码可读性好，减少了很多出错的机会


这样的a.hashcode() 有什么用，与a.equals(b)有什么关系。
默认调用 object 的hashcode方法，用于计算对象的内存地址。equals在不重写的情况下，使用的是object默认的 equals，调用==比较的也是对象的内存地址。


有没有可能2个不相等的对象有相同的hashcode。
可能，hash冲突


Java中的HashSet内部是如何工作的。
hashSet基于hashMap实现，因为 hashMap 的 key 是不能重复的，value 是统一的 public final static Object PRESENT = new Object()。
往 HashSet 中添加元素，首先判断元素（也就是key）是否存在，如果不存在则插入，如果存在则不插入，这样 HashSet 中就不存在重复值。


什么是序列化，怎么序列化，为什么序列化，反序列化会遇到什么问题，如何解决。
将 JVM 中的对象持久化保存到磁盘，只要一个类实现了 java.io.Serializable 接口，那么它就可以被序列化。
FileOutputStream fs = new FileOutputStream();
ObjectOutputSream os = new ObjectOutputSream(fs);
os.writeObject(对象);
os.close();
序列化的作用就是为了不同 jvm 之间共享实例对象;内存中的对象状态保存到一个文件中或者数据库中时候；当你想用套接字在网络上传送对象的时候；当你想通过RMI传输对象的时候；
transient 和 static 修饰的变量不参与序列化
serialVersionUID 不要改动


java8的新特性。
Lambda 表达式，Stream API，接口默认方法


什么情况下会发生栈内存溢出。
递归太深


JVM的内存结构，Eden和Survivor比例。
8:1:1


JVM内存为什么要分成新生代，老年代，永久代。新生代中为什么要分为Eden和Survivor。
永久代存放字符串常量池、类的基本信息，默认大小 4m，Jdk8 已经直接取消了 永久代 区域，新建了一个分配在本地内存的元空间。
因为新生代采用复制算法，Eden和to的存活对象复制到from，然后删除Eden和to中的对象，最后from和to互换。


JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。
-XX:+printGC(打印GC)；-XX:+PrintGCDetails；(打印GC细节)-XX:+PrintHeapAtGC；(在GC时打印堆状况)-XX:+TraceClassLoading；(打印class加载细节)
-Xmx（最大堆的空间)；-Xms（最小堆的空间）; -Xmn (设置新生代的大小)；-XX:NewRatio(新生代和老年代比例)；-XX:SurvivorRatio；
-Xss (设置栈空间的大小); -XX:+HeapDumpOnOutOfMemoryError；


你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。
新生代垃圾收集器： Serial，采用复制算法，单线程，在进行垃圾回收时会暂停其他所有工作线程(stop the world)
				ParNew，Serial 的多线程版，采用复制算法，在进行垃圾回收时会暂停其他所有工作线程(stop the world)
				Parallel Scavenge，多线程，采用复制算法，吞吐量优先,运行代码时间/(运行代码时间+垃圾收集时间)，最高效率地利用CPU时间，
				尽快地完成程序的运算任务,在进行垃圾回收时会暂停其他所有工作线程(stop the world)
				G1......

老年代垃圾收集器： Serial Old，采用标记-整理算法，单线程，在进行垃圾回收时会暂停其他所有工作线程(stop the world)
				Parallel Old,采用标记-整理算法，多线程，吞吐量优先,在进行垃圾回收时会暂停其他所有工作线程(stop the world)
				CMS 采用标记-清除算法，多线程，主要目标是获取最短垃圾回收停顿时间，真正意义上并发垃圾收集器，它第一次实现了让垃圾收集线程和用户线程同时工作。
				G1 基于标记-整理算法，高垃圾收集效率。可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。
				G1收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，
				同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。


垃圾回收算法的实现原理。
标记清除算法；标记整理算法；复制算法；分代收集算法
GC Root：栈中的对象


当出现了内存溢出，你怎么排错。
-XX:+HeapDumpOnOutOfMemoryError，Mat分析堆转储文件


JVM内存模型的相关知识了解多少，比如重排序，内存屏障，happen-before，主内存，工作内存等。
重排序指编译器和处理器为了优化程序性能而对指令序列进行重新排序的手段。
对于有数据依赖的代码，不会重排序，比如写后读、写后写和读后写；
happen-before是指A 操作 happen-before B 操作，只要保证结果正确，具体指令按什么顺序执行时可以重排序的。
as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。
程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。
join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

内存屏障
Store：将cache的数据刷新到内存中。Load：将内存存储的数据拷贝到cache中。
四种屏障：loadload、storestore、loadstore、storeload


简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。
bootStrap ClassLoader、extension ClassLoader 和 System ClassLoader
首先自己写一个加载器继承 ClassLoader，重写loadClass和findClass方法
两个类是否相同，需要他们的加载器相同！ 所以即使自己自定义加载器加载自己写的java.lang.String，系统也不认为该类就是真正的String


讲讲JAVA的反射机制。
反射就是对.class文件(字节码)进行一系列操作，包括获取所有变量、属性、方法、构造器...


g1和cms区别,吞吐量优先和响应优先的垃圾收集器选择。
CMS 是多线程老年代垃圾回收器，基于标记-清除算法，是真正意义上的并发垃圾收集器，追求最短的垃圾回收停顿时间。大概分为四步，首先初始标记(stop the world)，
标记出root可达的对象，然后并发标记，跟踪可达对象，再标记可达对象，接着重新标记(stop the world)，标记可达对象，最后并发清理。缺点是占用cpu，清理不彻底。
G1 基于对于新生代采用复制算法，对于老年代采用标记-整理算法，高垃圾收集效率。可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。
G1 垃圾收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，
每次根据所允许的收集时间，优先回收垃圾最多的区域。


怎么打出线程栈信息。
jstack


请解释如下jvm参数的含义： 
-server -Xms512m -Xmx512m -Xss1024K 
server: 指java启用JIT的Server Compiler，全局优化，优化比较慢，client Compiler 仅采用局部优化，优化比较快。
java堆最小512M，最大512M，栈空间大小1024K
-XX:PermSize=256m -XX:MaxPermSize=512m
永久代大小初始256m，最大512m
-XX:MaxTenuringThreshold=20
新生代晋升老年代的年龄阈值，默认15； 
-XX:MSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly。
当内存被占用达到80%时，启动full GC；指定cms使用手动设定的阈值full GC，否则只有第一次会在80%时GC，之后则自动调整


LongAdder和AtomicLong的区别
AtomicLong的原理是依靠底层的cas来保障原子性的更新数据，在要添加或者减少的时候，会使用死循环不断地cas到特定的值，从而达到更新数据的目的。
如果并发量大的时候会导致cas经常失败，相当于一直在自旋，白白浪费cpu资源。
LongAdder中会维护一个或多个变量，这些变量共同组成一个long型的"和"，当多个线程同时更新值时，如果他们之间不操作同一个值(cell)，则可以并行增减这组变量
的数值，若多个线程操作同一个cell，则通过cas方法尝试。"sum"方法会返回这组值的"和"。思路类似于concurrentHashMap，减小锁粒度。小并发情况下，效率和
AtomicLong差不多，高并发下LongAdder吞吐量明显更高，但有着更高的空间复杂度。


JMM Java内存模型
JMM定义了JVM在计算机内存RAM中的工作方式，JMM隶属于JVM。
JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程共享变量的副本。
基本变量 int a=-128~127，a变量存储在线程栈的局部变量表中，指向常量池中的-128~127；若不属于该范围，变量a和a的值都存储在线程栈中。
引用变量 Person a = new Person()，a变量存储在线程栈的局部变量表中，实际对象存储在堆中。

JMM 带来的问题
1.可见性问题
A线程在工作内存中修改了共享变量count，使之从1变成2，由于还没有flush到主内存，所以此时B线程读取到的count还是1。 需要引入Volatile
2.竞争现象
A、B线程同时在各自的工作内存中操作共享变量count，执行count++，结果可能为2或者3。需要引入Synchronized

3.重排序：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。
重排序类型
1、编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
2、指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3、内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

重排序与依赖性
1、写后读、写后写、读后写，这些语句顺序不能被改动，一旦顺序被重排序，执行结果就会被改变。
2、控制依赖性，flag变量是个标记，用来标识变量a是否已被写入，在use方法中是否对变量i进行操作依赖于if (flag)的判断。
在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果。处理器为了不闲置，会"猜测"flag为true，先行对i进行操作，万一后来发现flag其实是
false，大不了抛弃之前进行的操作，重新进行正确的操作。
但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。
3、as-if-serial：不管怎么重排序，单线程程序的执行结果不能被改变。为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序。
(这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。)

解决在并发下的问题
1、内存屏障——禁止重排序
JMM的四种内存屏障
LoadLoad Barrier           Load1，LoadLoad，Load2             确保Load1(从主内存装载到工作内存)数据装载，先于Load2及其后的所有指令     
LoadStore Barrier          Load1，LoadStore，Store2			 确保Load1数据装载，先于Store2(将数据从工作内存刷新到主内存)及其后的所有指令
StoreLoad Barrier          Store1，StoreLoad，Load2
StoreStore Barrier         Store1，StoreStore，Store2
2、临界区
临界区内的代码可以重排序（但JMM不允许临界区内的代码"逸出"到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点
做一些特别处理，虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法"观察"到线程A在临界区内的重排序。
这种重排序既提高了执行效率，又没有改变程序的执行结果。

Happens-Before规则要求前一个操作（执行的结果）对后一个操作可见...... 程序顺序规则、监视器锁规则、volatile变量规则、传递性、start()规则、join()规则、线程中断规则

volatile的内存语义
当写一个volatile变量时，JMM会把该线程对应的本地内存中的volatile变量值刷新到主内存。
当读一个volatile变量时，JMM会把该线程对应的本地内存的volatile变量置为无效，接着将从主内存中读取volatile变量。
volatile内存语义的实现——JMM对volatile的内存屏障插入策略：
在每个volatile写操作的前面插入一个StoreStore屏障。在每个volatile写操作的后面插入一个StoreLoad屏障。
在每个volatile读操作的前面插入一个LoadLoad屏障。在每个volatile读操作的后面插入一个LoadStore屏障。

锁的内存语义
当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。
当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。

synchronized的实现原理
使用monitorenter和monitorexit指令实现。
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处。
每个monitorenter必须有对应的monitorexit与之配对。

各种锁
锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。
偏向锁：大多数情况下，锁不存在多线程竞争，总是由同一线程获得。为了让线程获得锁的代价降低，引入了偏向锁。无竞争时不需要进行CAS操作来加锁和解锁。
轻量级锁：无竞争时通过CAS操作来加锁和解锁。（自旋锁——是一种锁的机制，不是状态）
重量级锁：真正的加锁操作

操作系统

Linux系统下你关注过哪些内核参数，说说你知道的。
fs.file-max 和 ulimit: 前者是指整个系统最大能打开的文件描述符的数量，后者指某个进程最大能打开的文件描述符的数量。

net.ipv4.tcp_fin_timeout = 2           #保持在FIN-WAIT-2状态的时间，使系统可以处理更多的连接。此参数值为整数，单位为秒。
net.ipv4.tcp_max_tw_buckets = 5000     #系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数值将立刻被清楚并输出警告信息。默认值为180000。对于squid来说效果不是很大，但可以控制TIME_WAIT套接字最大值，避免squid服务器被拖死。 
net.ipv4.tcp_tw_reuse = 1              #开启重用，允许将TIME_WAIT socket用于新的TCP连接。默认为0，表示关闭。
net.ipv4.tcp_tw_recycle = 1            #开启TCP连接中TIME_WAIT socket的快速回收。默认值为0，表示关闭。

net.ipv4.tcp_max_syn_backlog = 262144  #表示SYN队列的长度，预设为1024，这里设置队列长度为262144，以容纳更多的等待连接。
net.ipv4.tcp_syncookies = 1            #开启SYN cookie，出现SYN等待队列溢出时启用cookie处理，防范少量的SYN攻击。默认为0，表示关闭。
net.core.somaxconn = 16384             #定义了系统中Accept队列长度, 即完成三次握手的连接数量，对于一个经常处理新连接的高负载web服务环境来说，默认值为128，偏小。

net.ipv4.tcp_keepalive_time = 600      #keepalived启用时TCP发送keepalived消息的频度。
net.ipv4.tcp_keepalive_probes = 5      #TCP发送keepalive探测以确定该连接已经断开的次数。根据情形也可以适当地缩短此值。
net.ipv4.tcp_keepalive_intvl = 15      #探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒。对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值。
net.ipv4.ip_local_port_range = 1024 65000 #指定外部连接的端口范围。默认值为32768 61000。
net.ipv4.tcp_max_orphans = 16384       #表示系统中最多有多少TCP套接字不被关联到任何一个用户文件句柄上。如果超过这里设置的数字，连接就会复位并输出警告信息。这个限制仅仅是为了防止简单的DoS攻击。此值不能太小。 


Linux下IO模型有几种，各自的含义是什么。
阻塞IO：传统IO                             
非阻塞IO：用户线程不断轮询内核数据是否准备好了，长期占用cpu。       
多路复用IO：Reactor模式，由单个内核线程不断轮询多个socket channel状态。
信号驱动型IO：每个socket注册一个信号函数，当数据就绪时会发送一个信号给用户线程，然后用户线程进行IO读写。				   				   
异步IO：用户线程发起IO请求，立刻就可以去做自己的事情。用户线程和内核线程通过mmap映射同一块内存区域，内核会等待数据准备完成，然后将数据读取到共享内存。最后告知用户线程IO操作已经完成，可以直接使用数据了。                   


epoll和poll有什么区别。
poll:和select没啥区别。采用遍历fd的方式获取已经就绪的socket。因为是基于链表存储，所以没有单个线程监视文件描述符的数量限制。
	 仅支持水平触发模式，如果报告的fd没有被处理，下次轮询还是会报告该fd。
epoll:linux特有，支持水平触发和边缘触发；边缘触发:仅会通知一次fd就绪的消息，若没有处理，下次也不会通知了。
	 使用"事件"就绪通知方式，使用epoll_ctl注册fd，一旦该fd就绪，内核会调用callback回调机制激活fd，epoll_wait会收到通知。
	 没有并发连接限制(1G -> 10W连接)，不采用轮询方式。epoll采用mmap技术。
	 如果没有大量空闲连接，epoll效率和poll/select差不多


用一行命令查看文件的最后五行。
tail -n 5 filename
用一行命令查看文件的开头五行。
head -n 5 filename
查看文件的第三行到第五行
cat filename | tail -n +3 | head -n 5
将标准输出流和错误输出流都重定向到log
ls filename > log 2>&1


用一行命令输出正在运行的java进程。
jps


进程切换和线程切换的区别。
保护现场(保存程序计数器和相关寄存器)、恢复现场
虚拟内存：操作系统为每个进程提供的一种抽象，每个进程都有私有的、地址连续的虚拟内存。操作系统通过页表完成地址空间映射(虚拟内存映射物理内存)
		 页表存储在进程控制块PCB，切换页表以使用新的地址空间
进程切换：进程切换会导致虚拟内存的切换。虚拟内存映射到物理内存需要查找页表，为了加速查找，引入了缓存技术(快表TLB存放与单独的寄存器)加快查询，
		 显然每个进程都有属于自己的页表，进程切换后，缓存就失效了，导致缓存命中率降低，表现出来就是程序运行变慢。
线程切换：首先存储当前线程的本地数据(栈)，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。线程切换不会导致虚拟内存的切换，所以代价低。

引起上下文切换的原因
1、时间片用完，CPU正常调度下一个任务
2、被其他优先级更高的任务抢占
3、执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务
4、用户代码主动挂起当前任务让出CPU时间
5、多任务抢占资源，由于没有抢到被挂起
6、硬件中断


用户态切换到内核态的3种方式
1、系统调用
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如fork()创建新进程
2、异常
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
3、外围设备的中断
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前
执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作。


子进程和父进程
相同：UID和GroupID，用户信息，目录信息，环境(表)，已打开的文件描述符，堆栈，共享内存等。
不同：进程号PID、父进程号、自己打开的文件描述符和目录流的拷贝、不继承父进程的进程正文(text)，数据和其他锁定内存(memory locks),不继承异步输入和输出

经过fork()以后，父进程和子进程拥有相同内容的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只复制了自己的PCB块。而代码段、
数据段和用户堆栈内存空间并没有复制一份，而是与子进程共享。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。


top 命令之后有哪些内容，有什么作用。
进程号、进程所有者、进程名，ni静态优先级-20~19，越低优先级越高，pr动态优先级，virt进程使用的虚拟内存总量，shr共享物理内存大小，res进程使用的未被换出的物理内存大小
S进程状态， %CPU CPU使用率，%MEM 内存使用率，TIME 进程使用时间


source、sh、bash和.运行脚本有什么区别
./jiaoben.sh 需要脚本有执行权限，source、sh和bash不需要脚本有执行权限；source和.是在当前shell内执行脚本，同一个进程号，而sh和bash是另起一个进程执行脚本


僵尸进程和孤儿进程
僵尸进程:父进程还在运行，子进程却挂了，父进程没有使用wait来清理子进程信息，导致系统中还保留着一些子进程信息，浪费系统资源
孤儿进程:子进程还在运行，父进程却挂了，子进程会交给init(PID=1)进程统一管理，完成状态收集工作


linux下进程的五种状态
就绪状态，运行状态，中止状态，
可中断睡眠状态:进程未获得它所申请的资源而处在等待状态。一旦资源有效或者有唤醒信号，进程会立即结束等待而进入就绪状态。
不可中断睡眠状态:进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。
僵死状态:僵尸进程，虽然线程已死亡，但是系统中还残留部分信息


多线程

多线程的几种实现方式，什么是线程安全。
继承Thread类、实现Runnable接口、实现Callable接口


volatile的原理，作用，能代替锁么。
不能代替锁。被volatile修饰的变量每次都从主存中读取，并且禁止指令重排序。volatile变量是一种比sychronized关键字更轻量级的同步机制


画一个线程的生命周期状态图。
就绪状态，运行状态，阻塞状态，结束状态
结束状态:程序正常执行完毕/调用stop(会释放锁)
阻塞状态:比如调用sleep(不会释放锁)，阻塞式IO读写，没有获得监视器，wait(释放锁)某个notify()，调用suspend(不会释放锁)，yield(不会释放锁)


sleep和wait的区别。
sleep不会释放锁，wait会释放锁


sleep和sleep(0)的区别。
sleep(long time) 线程在指定时间内不参与cpu竞争；sleep(0) 线程会从阻塞队列直接回到就绪队列，参与cpu竞争，是想让其他线程也有得到cpu运行的机会，


Lock与Synchronized的区别 。
Synchronized是内置锁，处于jvm层面，Lock是java类；
Synchronized无法判断是否获取锁，Lock可以判断是否获取到锁；
Synchronized会自动释放锁，Lock需在finally中手工释放锁；
Synchronized会导致无法获得锁的线程一直等待，Lock可以tryLock(time)，若还不能获得锁则执行别的逻辑
Synchronized可重入、不可中断、非公平，Lock可重入、可中断、可公平、可不公平
Synchronized锁适合代码量少的同步问题，Lock锁适合代码量大的同步问题。


synchronized的原理是什么，一般用在什么地方(比如加在静态方法和非静态方法的区别，静态方法和非静态方法同时执行的时候会有影响吗)。
同步代码块是使用MonitorEnter和MoniterExit指令实现的，在编译时，MonitorEnter指令被插入到同步代码块的开始位置，MoniterExit指令被插入到同步代码块的结束位置和异常位置。
加在静态方法前锁定的是整个类，加在非静态方法前锁定的是当前对象。
修饰静态方法，锁是加在类上的，类的所有对象竞争一把锁;修饰非静态方法，锁加在单个对象上，不同对象间没有竞争关系。


解释以下名词：重排序，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁。
重排序:编译器和处理器为了优化程序性能而对指令进行重新排序
自旋锁:为了编译线程上下文切换带来的损耗，所以让线程空等待
偏向锁:在没有实际竞争的情况下，自始至终都只有一个线程在使用锁，降低获取锁的消耗，仅要一次CAS操作
轻量级锁:无实际竞争，多个线程交替使用锁，允许短时间的锁竞争(自旋)
可重入锁:线程可以进入它拥有的锁所同步的代码块
公平锁:加锁前先查看是否有排队等待的线程，有的话优先处理排在前面的线程，先来先得
非公平锁:随机获得锁
悲观锁:假设一定会发生并发冲突，通过阻塞其他所有线程来保证数据的完整性。比如Synchronized
乐观锁:假设不会发生并发冲突，不加锁去完成某项更新，如果冲突就返回失败。比如CAS机制


用过哪些原子类，他们的原理是什么。
AtomicInteger、AtomicLong、AtomicBoolean，CAS


JUC下研究过哪些并发工具，讲讲原理。
CountDownLatch:使一个线程等待其他线程都执行完毕后才开始执行
CyclicBarrier:所有线程相互等待，只有当所有线程都到达某个点之后才能开始接着往下做
Semaphore:限制同一时刻访问某种资源的线程数量
Exchanger:交换器,两个线程到达同步点后交换数据


用过线程池吗，如果用过，请说明原理，并说说newCache和newFixed有什么区别，构造函数的各个参数的含义是什么，比如coreSize，maxsize等。
ThreadPoolExecutor(......)
corePoolSize核心线程数量，maxsize核心线程+非核心线程数量，keepAliveTime非核心线程最大闲置时间，timeUnit时间单位，workQueue等待队列
threadFactory工厂方法，Reject拒绝机制
几种常用的线程池
CachedThreadPool():new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue<Runnable>());
				   核心线程为0，非核心线程数量几乎无限制，60秒限制销毁线程，等待队列为同步队列，出队和入队必须同时进行。
				   快速处理大量耗时较短的任务，如Netty的NIO接受请求时，可使用CachedThreadPool。
FixedThreadPool:new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>());
			    核心线程数为nThread，没有非核心线程，等待队列几乎无限制，可以存储大量任务。
			    可用于Web服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞。
SingleThreadPool:仅一个核心线程，一个一个的执行任务
ScheduledThreadPool:隔多久执行一个任务


线程池的关闭方式有几种，各自的区别是什么。
shutDownNow:线程池拒绝接收新提交的任务，同时立马关闭线程池，线程池里的任务不再执行。
shutDown:线程池拒绝接收新提交的任务，同时等待线程池里的任务执行完毕后关闭线程池。
awaitTermination 和 shutDown 配合使用


假如有一个第三方接口，有很多个线程去调用获取数据，现在规定每秒钟最多有10个线程同时调用它，如何做到。
ScheduledThreadPool + Semaphore


spring的controller是单例还是多例，怎么保证并发的安全。
Controller 默认情况下是单例模式


ThreadLocal用过么，用途是什么，原理是什么，用的时候要注意什么。
用于保存某个共享变量的副本，修改、删除不会影响别的线程。Thread类中有一个成员变量属于ThreadLocalMap类，一个定义在ThreadLocal类中的内部类
ThreadLocalMap<ThreadLocal，Object>成员变量，以ThreadLocal对象为key


如果让你实现一个并发安全的链表，你会怎么做。
ConcurrentLinkedQueue，Collections.synchronizedList()


有哪些无锁数据结构，他们实现的原理是什么。
CAS


讲讲java同步机制的wait和notify。
都是Object方法，只能在同步代码块中调用，wait释放锁、线程阻塞，notify唤醒等待在监视器上的线程，使之重新加入cpu竞争


CAS机制是什么，如何解决ABA问题。
AtomicStampedReference，加版本戳/时间戳


多线程如果线程挂住了怎么办。
因为wait挂住，需要等待notify/notifyAll才能进入可执行状态
因为sleep挂住，需要等待指定时间
因为join挂住，需要等待之前的线程都完成才能执行
因为suspend挂住，需要等待resume唤醒


countdowlatch和cyclicbarrier的内部原理和用法，以及相互之间的差别(比如countdownlatch的await方法和是怎么实现的)。
CountDownLatch等待前面的线程都完成之后，后面的线程才能开始执行，递减，不可重复利用
执行countdown的某个子线程可能会因为某些原因无法执行countdown，导致countDownLatch的倒计时不能减到0，await线程一直阻塞下去。
CyclicBarrier线程相互等待，知道所有线程都完成任务到达屏障点，再一块往下执行，递加，可重复利用


对AbstractQueuedSynchronizer了解多少，讲讲加锁和解锁的流程，独占锁和公平锁加锁有什么不同。
AQS定义两种资源共享方式:独占，只有一个线程能执行，如ReentrantLock；共享，多个线程可同时执行，如Semaphore。
AQS为Java中的并发同步组件提供统一的底层支持，关键点:同步状态和同步队列
同步状态state为0，说明当前锁已经被占，需要添加到同步队列中；同步状态state为1，说明线程可以获取到锁，共享锁state大于1
同步队列:它是一个双端队列，遵循FIFO原则，主要作用是用来存放在锁上阻塞的线程，当一个线程尝试获取锁时，如果已经被占用，那么当前线程就会被构造成一个Node
	    节点插入到同步队列的尾部。队列的头节点是成功获取锁的节点，当独占锁的头节点线程释放锁时，会唤醒其直接后继节点并释放当前头节点的引用；
	    当共享锁头节点释放锁，会唤醒其后面的所有节点 


使用synchronized修饰静态方法和非静态方法有什么区别。
修饰静态方法，锁定的是这个类，修饰非静态方法锁定的是这个对象


简述ConcurrentLinkedQueue和LinkedBlockingQueue的用处和不同之处。
LinkedBlockingQueue 是一个基于单向链表的、范围任意的（其实是有界的）、FIFO 阻塞队列。 
ConcurrentLinkedQueue是一个基于链节点的无界线程安全队列，


导致线程死锁的原因？怎么解除线程死锁。
在死锁时，线程间相互等待资源，而又不释放自身的资源，导致无穷无尽的等待，其结果是系统任务永远无法执行完成。
释放某个线程拥有的资源，


用过读写锁吗，原理是什么，一般在什么场景下用。
ReentrantReadWriteLock 适用读比写多的场景。基于AQS实现同步功能，将同步状态state掰成两份用，读与写互斥，支持重入，但是可以从写锁降级为读锁，反之不行


延迟队列的实现方式，delayQueue和时间轮算法的异同。
延迟一段时间后触发事件
delayQueue:采用PriorityQueue实现，二叉堆实现，在插入和获取时都是O(logn)
时间轮:一个轮子，有8个“槽”，可以代表未来的一个时间。如果以秒为单位，中间的指针每隔一秒钟转动到新的“槽”上面，就好像手表一样。如果当前指针指在1上面，
	  我有一个任务需要4秒以后执行，那么这个执行的线程回调或者消息将会被放在5上。采用数组或者环形链表实现。
DelayQueue由于涉及到排序，需要调堆，插入和移除的复杂度是O(lgn)，而时间轮在插入和移除的复杂度都是O(1)。


TCP与HTTP

http1.0和http1.1有什么区别。
缓存处理，1.1引入了更多的缓存控制策略；
带宽优化，1.1允许只请求资源的某个部分；
新增错误码，1.1新增了24个错误状态响应码；
Host头处理，HTTP1.1的请求消息和响应消息都应支持Host头域，一台服务器上可能有多台虚拟服务器共享ip，所以请求需要带hostname
长连接，1.1默认开启keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。


TCP三次握手和四次挥手的流程，为什么断开连接要4次,如果握手只有两次，会出现什么。
FIN_WAIT1 ---FIN M--->  CLOSE_WAIT

FIN_WAIT2 <--ACK M+1--

TIME_WAIT <---FIN N---   LAST_ACK

          --ACK N+1-->   CLOSED
断开的时候，只有当服务器端所有的报文都发送完了，它才能发送FIN报文，因此不能一起发送。故需要四步握手。
如果只有两次握手，可能会导致服务器端建立一些实际不应该建立的连接。比如服务器接收到本来以为已经丢失的数据报，就会返回客户端一个syn和ack消息，
然后服务器认为我已经建立了一个新连接，其实根本没有人来连接服务器，白白浪费资源。
如果是三次建立连接，服务端需要等待客户端的确认，而客户端并不会发送ack，所以就不会建立连接。


TIME_WAIT和CLOSE_WAIT的区别。
TIME_WAIT位于客户端FIN_WAIT1和FIN_WAIT2之后，他需要等待2msl(最大报文生存时间)时长......
CLOSE_WAIT位于服务端接收到FIN_WAIT1发来FIN之后
TIME_WAIT状态用来重发可能丢失的ACK报文。 
TIME_WAIT表示主动关闭，CLOSE_WAIT表示被动关闭。


说说你知道的几种HTTP响应码，比如200, 302, 404。
200 ok 一切正常 
302 暂时性转移 重定向
404 页面未找到 


当你用浏览器打开一个链接（如：http://www.javastack.cn）的时候，计算机做了哪些工作步骤。
请求dns服务器解析域名得到请求主机ip，发起tcp建立请求，然后发起http请求，服务器接收http请求并处理，服务器响应，返回html，浏览器对页面进行渲染，断开连接


TCP/IP如何保证可靠性，说说TCP头的结构。
如何保证可靠性：
1、收到发送端发出数据包会返回确认信号ACK。
当接收端接收到来自发送端的数据包之后，会返回一个已收到消息的ACK(序列号+1)

2、针对数据包丢失或者出现超时的重发机制。
情况一、数据包丢失：重发即可
情况二、接收端ACK丢失：会导致接收端收到重复数据包，造成网络资源浪费，需要引入滑动窗口机制
超时时间：TCP在每次发包时都会计算往返时间及其偏差，将这个"往返时间+偏差"，重发超时就是比这个总和值要稍大一点的值。
MSS：最大消息长度，在建立TCP连接时，确定发送单个数据包的大小(选择发送端和接收端能适应的较小的MSS值)。最理想的情况是，最大消息长度MSS正好是网络层中不被分包处理的最大数据长度。

3、针对数据包到达接收端主机顺序乱掉的顺序控制。
发送端要发送的数据由很多数据包构成。网络层仅保证单个数据包完整性，若传输层发给网络层的数据包过大，会被分包，到达接收端网络层会被组包，只有一个
完整的数据包才会被交给传输层，否则会被丢弃。网络层不保证数据包一定到达，需要传输层保证，所以TCP有超时重传机制。
TCP数据包都有序列号，即使B比A先到达了，也会等A到达之后，先把A提交给应用层，再把B提交给应用层，从而保证同一条TCP链接，先发的包先到。
UDP数据包没有序列号，所以不会将网络层乱序到达的数据包按顺序排序，需要应用层自己排序。

4、针对高效传输数据包的滑动窗口控制。
ACK不再以每个段(比如1~1000、1001~2000)为单位进行确认了，发送端在发送了一个段之后，没必要一直等待对端主机的确认应答信号，而是继续发送。
窗口大小，指的就是无需等待接收端返回ACK而可以持续发送的数据的最大值。
滑动窗口左外侧是已经确认对端收到的数据，右外侧是还未发送的数据。当收到ACK信号之后，会把滑动窗口的位置滑动到确认应答的序列号的位置。
若发生数据丢包：
情况一、数据包丢失。比如接收端没收到1001~2000这段数据，接收端会一直返回"下一次数据是1001"提醒发送端缺失了哪一段数据。
情况二、ACK确认号丢失。比如接收端没有成功发送"已成功接收1001~2000"段数据，只要下一次接收端返回给发送端"已成功接收2001~3000"段数据，就能反推出之前的数据其实已经被收到了。

5、针对避免网络拥堵时候的流量控制。
可以让发送端根据接收端的实际接收能力来控制自己发送的数据量。接收端的缓冲区一旦面临数据溢出，就会主动减小窗口的大小再次发送给发送端，从而可以控制数据发送量
若接收端缓冲区满了之后会把窗口大小设置为0，发送端会停止发送数据直到接收端通知(发送端也会时不时的发送一个叫做"探测窗口"的数据包，仅包含一个字节，以获取最新的窗口大小)

6、针对避免刚开始启动的时候一下子发送大量数据包而导致网络瘫痪的慢启动算法和拥塞控制。
在通信一开始的时候会使用"慢启动"算法对发送的数据量进行控制。为了在发送端调节所要发送的数据量，定义了一个叫做"拥塞窗口"的概念。在慢启动刚开始的
时候，把这个拥塞窗口设置为1个MSS（1个最大消息长度）发送数据，随着数据包的每次成功往返，拥塞窗口会以1、2、4、8形式增长，直到到达上限。
当发生超时时，会把拥塞窗口上限设置为原来的一半，拥塞窗口回到最小值1MSS。	
然后，在发送数据的时候，把拥塞窗口和滑动窗口的大小作比较，按照它们当中较小的那个值来发送比其还要小的数据量。

TCP头结构：
源端口，目的端口，序列号，确认号，首部长度字段，六位标志位，窗口大小，校验和，紧急指针


如何避免浏览器缓存。
请求头中设置Cache-Control:max-age=0，告诉浏览器不要缓存信息
POST请求无法被缓存；动态请求不能被缓存

动态请求和静态请求、动态页面和静态页面
html、htm后缀结尾是静态页面，ASP、PHP、JSP、ASP.net、Perl、或CGI结尾是动态页面
静态页面网页不包含在服务器端运行的任何脚本，网页上的每一行代码都是由网页设计人员预先编写好后，放置到Web服务器上的，在发送到客户端浏览器之后不再发生任何变化。
动态页面实际上并不是独立存在于服务器上的网页文件，只有当用户请求时服务器才返回一个完整的网页；
动态页面上的内容存在于数据库中，根据用户发出的不同请求，其提供个性化的网页内容；
动态页面内容不是存在于页面上，而是在数据库中，从而大大降低网站维护的工作量；
采用动态网页技术的网站可以实现更多的功能，如用户注册、用户登录、在线调查、用户管理、订单管理等等，静态页面则无法实现这些功能。


如何理解HTTP协议的无连接和无状态性。
无连接:请求时建连接、请求完释放连接，以尽快将资源释放出来服务其他客户端。但是因为现在网页变得越来越复杂，里面可能嵌入了很多图片，这时候每次访问图片都需要
	  立一次 TCP 连接就显得很低效。Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免重新建立连接。
无状态:协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是发送完，
	  不会记录任何信息。但是当大量客户端与服务器进行动态交互的 Web 应用程序出现之后，引入了cookie和session。


简述Http请求get和post的区别以及数据包格式。
get请求将参数放置于url后面，post请求将参数放在请求体里，更安全；
get提交的数据最多1024字节，post能传输的数据量很大。


HTTP有哪些method
get、post、put、delete、head、options、trace、patch


简述HTTP请求的报文格式。
请求报文:请求行(请求方法、url、http版本)、请求头(一堆的键值对)、请求体(get方法没有请求体，post方法有请求体)
响应报文:响应行(http版本、状态码、状态码描述符)、响应头(一堆键值对)、响应体(服务器返回给客户端的文本信息)


HTTP的长连接是什么意思。
HTTP1.1规定了默认保持长连接，数据传输完成了保持TCP连接不断开（不发RST包、不四次握手），等待在同域名下继续用这个通道传输数据
keepalived,不要断开连接，后续如果还有请求，直接在当前连接上请求。


HTTPS的加密方式是什么，讲讲整个加密解密流程。
HTTPS 443端口，HTTP+SSL/TLS
客户端发起https请求。
采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。
传送证书给客户端，这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。
客户端解析证书，验证该证书是否有效，如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密。
传送加密信息，让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把要传输的内容通过该值进行对称加密。除非知道私钥，不然无法获取内容。


Http和Https的三次握手有什么区别。
当浏览器使用https时，浏览器会先同SSL/TLS进行通信，然后SSL/TLS再同tcp进行通信


REST和RPC的区别
REST是面向资源的（URL表示资源，HTTP动词表示动作），RPC是面向动作的（方法调用）
RPC的编程模型较重量级，REST的编程模型更轻量级
RPC 自定义tcp+json 传输更轻量化， rest http报文会包含很多无用的信息，效率低
对外开放的api采用rest，内部通信采用rpc


Session和cookie的区别。
Session 存放在服务器端的客户端信息，通过sessionID进行标识，客户端每次访问都要带着这个id(通过cookie或者url重写)。会占用服务器性能
Cookie 服务端存放在客户端的信息，不是很安全



消息队列

消息队列的使用场景。
异步处理、应用解耦、流量削峰、日志处理


如何保证消息的有序性。
思路：1)单线程消费来保证消息的顺序性；
     2)对消息进行编号，消费者处理时根据编号判断顺序。 
RabbitMQ、Kafka和RocketMQ采用思路一
MQ里创建多个queue，有顺序要求的数据按顺序放入同一queue，同一个消费者从该queue一个一个消费数据；
MQ只创建一个queue，仅对应一个消费者，消费者内部维护一个队列，按顺序处理数据；
ACtiveMQ采用思路二
activeMq 里面有 messageGroups 属性，可以指定 JMSXGroupID，消费者会消费指定的 JMSXGroupID。即保证了顺序性，又解决负载均衡的问题。


用过哪些MQ，和其他mq比较有什么优缺点，MQ的连接是线程安全的吗，你们公司的MQ服务架构怎样的。
ActiveMQ：成熟的产品，协议支持好。大规模应用场景有待考证，社区不活跃
RabbitMQ：基于erlang天生支持高并发，性能较好，已经得到大规模应用场景验证，社区活跃。集群不支持动态扩展。
RocketMQ：性能优秀，支持多种消费，集群消费、广播消费等。产品较新，缺少文档，对已有系统而言不能兼容。


MQ系统的数据如何保证不丢失。
生产者 -> MQ -> 消费者
1)消费者实例宕机的时候，如何保障数据是不会丢失？
消费者收到一个消息会发送ack给MQ，MQ收到ack之后才会删除这个消息，如果消费者还没发送ack，消费者自己就宕机了，MQ会认为消费者宕机，就会重新投递
这条消息给其他的消费者实例。通过这种机制保证消费者实例宕机时，数据不会丢失。
2)如何保证生产者投递到消息中间件(MQ)的消息不丢失？
生产者需要开启confirm模式，投递消息到MQ，如果MQ将消息持久化到磁盘之后，必须要回传一个confirm消息给生产者。如果生产者接收到了confirm消息，就
知道已经持久化到磁盘了。如果没有接收到confirm消息，就说明这条消息可能丢失了，此时需要重新投递消息到MQ，确保消息不要丢失。


rabbitmq如何实现集群高可用。
单一模式、普通模式、镜像模式
单一模式：最简单、非集群模式
普通模式：默认的集群模式。消息实体只存在于其中一个节点rabbit01(或者rabbit02)，rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。
当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费该消息时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把rabbit01中的
消息实体取出并经过rabbit02发送给consumer。所以consumer应尽量连接每一个节点，不然只能从特定的服务器上取数据。当rabbit01节点故障后，rabbit02
无法获取rabbit01中的消息。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。
镜像模式：消息实体会主动在节点间同步，而不是在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量
过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。难以水平扩展


kafka吞吐量高的原因。
磁盘顺序读写 + 零拷贝(基于内核PageCache、Sendfile) + 分区
PageCache：当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页
才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。
Sendfile：传统的网络I/O操作流程，大体上分为以下4步。
1. OS从硬盘把数据读到内核区的PageCache。
2. 用户进程把数据从内核区Copy到用户区。
3. 然后用户进程再把数据写入到Socket，数据流入内核区的Socket Buffer上。
4. OS再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。

磁盘顺序读写:kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
零拷贝:跳过"用户缓冲区"的拷贝(2和3步)，建立一个磁盘空间和内存的直接映射，数据不再复制到"用户态缓冲区"
分区:kafka的topic中的内容可以被分为多份partition,每个partition又分为多个segment,每次操作仅针对一小部分，增加并行操作的能力


kafka 和其他消息队列的区别，kafka 主从同步怎么实现。
Producer ：消息生产者，就是向 kafka broker 发消息的客户端
Consumer ：消息消费者，向 kafka broker 取消息的客户端
Topic ：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic
Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。
Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上。每个 partition 是一个有序的队列。partition 中的每条消息
都会被分配一个有序的 id（offset）。kafka 只保证按一个 partition 中的顺序将消息发给 consumer，不保证一个 topic 的整体(多个partition间)的顺序。

kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。
rabbitMQ在吞吐量方面稍逊于kafka，但是支持对消息的可靠传递，支持事务，不支持批量的操作；可以采用内存或者硬盘进行持久化。
kafka的broker支持主备模式。rabbitMQ支持miror的queue，主queue失效，miror queue接管。
kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker
信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。rabbitMQ的负载均衡需要单独的loadbalancer进行支持。

kafka 主从同步：leader和follower


利用mq怎么实现最终一致性。
CAP理论(一致性、可用性、分区容错性)，不可能都满足
在互联网领域的绝大多数场景，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。
生产者 ->  MQ -> 消费者
1)生产者给MQ发送事务消息，MQ收到消息后返回ACK，并暂时设置该消息对Consumer不可见
2)生产者开始执行本地事务逻辑，若执行成功则告知MQ确认该消息并push给消费者，若不成功则告知MQ删除该消息
3)若MQ发送消息给消费者，消费者开始执行本地事务逻辑，如果执行成功则向MQ返回"消费成功"，反之出现异常则需要返回"消费失败"，以便MQ再次Push该消息


MQ有可能发生重复消费，如何避免，如何做到幂等。
生产者 -> MQ 重复发送
此时重发是生产者发起的。
对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，全局唯一，业务无关性，对消息发送方和消息接收方屏蔽。
MQ -> 消费者
此时重发是MQ-server发起的。
业务消息体中，必须有一个biz-id，全局唯一，对MQ透明，与业务相关，比如支付id、订单id，由消费者自己负责判重、保证幂等性。


MQ消息可以设置过期时间么，过期了你们一般怎么处理？MQ快满了如何处理？
RabbitMQ消息可以设置过期时间。手动找出过期数据，批量重导。
修复消费者，紧急扩容MQ，新建topic，partition*10，queue*10，consumer*10


缓存

常见的缓存策略有哪些，如何做到缓存(比如redis)与DB里的数据一致性，你们项目中用到了什么缓存系统，如何设计的。
缓存策略的分类：
           1）基于访问的时间：此类算法按各缓存项被访问时间来组织缓存队列，决定替换对象。如LRU
           2）基于访问频率：此类算法用缓存项的被访问频率来组织缓存。如LFU、LRU2、2Q、LIRS。
           3）访问时间与频率兼顾：通过兼顾访问时间和频率。使得数据模式在变化时缓存策略仍有较好性能。如FBR、LRUF、ALRFU。
		     多数此类算法具有一个可调或自适应参数，通过该参数的调节使缓存策略在基于访问时间与频率间取得一个平衡。
           4）基于访问模式：某些应用有较明确的数据访问特点，进而产生与其相适应的缓存策略。如专用的VoD系统设计的A&L缓存策略，同时适应随机、顺序两种访问模式的SARC策略。

思路：保持缓存的"新鲜性"，每当数据发生变化的时候（数据被修改，或被删除的情况下），要同步更新缓存信息，确保用户不会在缓存取到旧的数据。
解决办法：对于读操作，若缓存没有命中，读取数据库，然后将数据set到缓存；
		 对于写操作，先删除缓存，然后修改数据库，下次查询该条数据时再将其加入缓存。


如何防止缓存穿透、缓存击穿、缓存雪崩和缓存刷新。
缓存穿透：收到一个请求，但是该请求缓存中不存在，只能去数据库中查询，然后放进缓存。但当有好多请求同时访问同一个数据时，业务系统把这些请求全发到
了数据库；或者恶意构造一个逻辑上不存在的数据，然后大量发送这个请求，这样每次都会被发送到数据库，最终导致数据库挂掉。
1)最常见是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，不要发送到数据库；
2)缓存空结果，就是对查询不存在的数据也记录在缓存中，这样就可以有效的减少查询数据库的次数。

缓存击穿：对于热点数据，当缓存失效的一瞬间，所有的请求都被下放到数据库去请求更新缓存，数据库被压垮。
1)加全局锁，就是所有访问某个数据的请求都共享一个锁，获得锁的那个才有资格去访问数据库，其他线程必须等待。但现在大部分系统都是分布式的，
本地锁无法控制其他服务器也等待，所以要用到全局锁，比如Redis的setnx实现全局锁。
2)对即将过期的数据进行主动刷新，比如新起一个线程轮询数据，或者把所有的数据划分为不同的缓存区间，定期分区间刷新数据。

缓存雪崩：当我们给所有的缓存设置了同样的过期时间，当某一时刻，整个缓存的数据全部过期了，然后瞬间所有的请求都涌向了数据库，数据库就崩掉了。
划分更小的缓存区间，按区间过期；要么给每个key的过期时间加一个随机值，避免同时过期，达到错峰刷新缓存的目的。

缓存刷新：一般在insert、update、delete操作后就需要刷新缓存，如果不执行就会出现脏数据。但当缓存请求的系统崩掉后，返回给缓存的值为null。


缓存更新策略。
对时效性要求高的缓存数据，但发生变更的时候，直接采取数据库和Redis/MemCached(分布式)缓存双写方案，提高缓存时效性
对时效性不高的数据，当发生变更之后，采用MQ异步通知的方式，通过数据生产服务来监听MQ消息，然后异步拉取数据库数据更新tomcat jvm(本地缓存)和
Redis/MemCached(分布式)缓存，本地缓存过之后就可以从redis中拉取新的数据更新nginx缓存。


缓存数据过期检测。
定时扫描：将每个设置了过期时间的key放到一个独立的hash中，默认每秒定时遍历这个hash而不是整个空间
惰性策略：客户端访问的时候，会对这个key的过期时间进行检查，如果过期了就立即删除。


redis的list结构相关的操作。
lpush，lpop，rpush，rpop，llen，lrange，


Redis的数据结构都有哪些。
String、List、Hash、Set、Sorted Set


Redis的使用要注意什么，讲讲持久化方式，内存设置，集群的应用和优劣势，淘汰策略等。
使用注意：1)从数据存储方面考虑
		 在能表达业务含义的基础上，尽可能缩减key长度；在不影响使用的情况下，缩减value大小，比如value是文本或者图像，可以压缩之后在存入redis，
		 value是序列化对象，可以考虑不序列化非必要的业务属性。
		 减少键值对的数量，对于大量的String类型的小对象，可以尝试使用Hash的形式组合他们，在Hash对象内Field数量少于1000，且Value的字符长度
		 小于40时，内部使用ziplist的编码形式，能够极大的降低小对象占据的内存空间。
		 Redis内维护了一个[0-9999]的整数对象池，类似Java内的运行时常量池，只创建一个常量，使用时都去引用这个常量，所以当存储的value是这个
		 范围内的数字时均是引用向都一个内存地址，所以能够降低一些内存空间耗费。
		 2)从数据访问方面考虑
		 redis是数据库，所以也需要"连接"数据库。
		 复用连接，将多次查询合并成一次查询，PipeLine,批量的将数据写入redis，允许一定比例的写入失败
		 对于多次String类型的查询，使用mget，将多次请求合并为一次，能有效提高响应速度
		 对于Hash内多个Field查询，使用hmget，起到和mget同样的效果
持久化方式：RDB时间点快照；AOF记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集
内存设置：maxmemory used_memory
虚拟内存： vm-enabled yes


redis2和redis3的区别，redis3内部通讯机制。
集群方式的区别：Redis3采用Cluster，Redis2采用客户端分区方案和代理方案
通信过程说明：
1）集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000。
2）每个节点在固定周期内通过特定规则选择几个节点发送ping消息。
3）接收到ping消息的节点用pong消息作为响应。


当前redis集群有哪些玩法，各自优缺点，场景。
 1）数据共享：Redis提供多个节点实例间的数据共享，也就是 Redis A,B,C 彼此之间的数据是同步的，同样彼此之间也可以通信，而对于客户端操作的keys
 是由Redis系统自行分配到各个节点中。
 2）主从复制：Redis的多个实例间通信时，一旦其中的一个节点故障，那么Redis集群就不能继续正常工作，所以需要一种复制机制（Master-Slave）机制，
做到一旦节点A故障了，那么其从节点A1和A2就可以接管并继续提供与A同样的工作服务，当然如果节点A,A1,A2节点都出现问题，那么同样这个集群不会继续
保持工作，但是这种情况比较罕见，即使出现了，也会及时发现并修复使用。建议：部署主从复制机制（Master-Slave）。
 3）哈希槽值：Redis集群中使用哈希槽来存储客户端的keys，而在Redis中，目前存在16384个哈希槽，它们被全部分配给所有的节点，正如上图所示，
所有的哈希槽值被节点A，B，C分配完成了。


Memcache的原理，哪些数据适合放在缓存中。
MemCache的数据存放在内存中，最大键长为250字节，可以接受的储存数据不能超过1MB(Redis 键值均为512MB)
1）访问数据的速度比传统的关系型数据库要快，因为Oracle、MySQL这些传统的关系型数据库为了保持数据的持久性，数据存放在硬盘中，IO操作速度慢
2）MemCache的数据存放在内存中同时意味着只要MemCache重启了，数据就会消失
3）既然MemCache的数据存放在内存中，那么势必受到机器位数的限制，32位机器最多只能使用2GB的内存空间，64位机器可以认为没有上限。
变化频繁、不需要实时入库、可靠性要求不高的数据(比如用户在线状态、在线人数..)门户网站的新闻等，觉得页面静态化仍不能满足要求，可以放入到memcache中.(配合jquey的ajax请求)。


redis和memcached 的内存管理的区别。
MongoDB其实只是一种非关系型数据库，其优势在于可以存储海量数据，具备强大的查询功能，因此不宜用于缓存数据的场景。
Memcached单个key-value大小有限，一个value最大只支持1MB，而Redis最大支持512MB
Memcached只是个内存缓存，对可靠性无要求；而Redis更倾向于内存数据库，因此对可靠性方面要求比较高
1)性能上：
性能上都很出色，具体到细节，由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。
而在100K以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。
 
2)内存空间和数据量大小：
MemCached可以修改最大内存，采用LRU算法。Redis增加了VM的特性，突破了物理内存的限制。
 
3)操作便利上：
MemCached数据结构单一，仅用来缓存数据，而Redis支持更加丰富的数据类型，也可以在服务器端直接对数据进行丰富的操作,这样可以减少网络IO次数和数据体积。
 
4)可靠性上：
MemCached不支持数据持久化，断电或重启后数据消失，但其稳定性是有保证的。Redis支持数据持久化和数据恢复，允许单点故障，但是同时也会付出性能的代价。
 
5)应用场景：
Memcached：动态系统中减轻数据库负载，提升性能；做缓存，适合读多写少，大数据量的情况（如大量查询用户信息、好友信息、文章信息等）。
Redis：适用于对读写效率要求都很高，数据处理业务复杂和对安全性要求较高的系统（如新浪微博的计数和微博发布部分系统，对数据安全性、读写要求都很高）。


Redis的并发竞争问题如何解决，了解Redis事务的CAS操作吗。
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端
对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：
【1】客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
【2】服务器角度，利用setnx实现锁。MULTI，EXEC，DISCARD，WATCH 四个命令是 Redis 事务的四个基础命令。其中：
☆ MULTI，告诉 Redis 服务器开启一个事务。注意，只是开启，而不是执行
☆ EXEC，告诉 Redis 开始执行事务
☆ DISCARD，告诉 Redis 取消事务
☆ WATCH，监视某一个键值对，它的作用是在事务执行之前如果监视的键值被修改，事务会被取消、无法执行。可以通过watch实现乐观锁


redis的持久化的机制，aof和rdb的区别。
一种是RDB持久化（将Reids在内存中的数据库记录定时dump到磁盘上的RDB文件），另外一种是AOF持久化（将Reids的操作日志以追加的方式写入文件）。
区别：RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
	 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。
RDB性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。
如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。


redis的集群怎么同步数据的。
1）master可以有多个slave
2）除了多个slave连到相同的master外，slave也可以连接其他slave形成图状结构
3）主从复制不会阻塞master。也就是说当一个或多个slave与master进行初次同步数据时，master可以继续处理client发来的请求。相反slave在初次同步数据时则会阻塞不能处理client的请求
4）主从复制可以用来提高系统的可伸缩性,我们可以用多个slave专门用于client的读请求，比如sort操作可以使用slave来处理。也可以用来做简单的数据冗余
5）可以在master禁用数据持久化，只需要注释掉master配置文件中的所有save配置，然后只在slave上配置数据持久化


知道哪些redis的优化操作。
1)根据业务需要选择合适的数据类型，并为不同的应用场景设置相应的紧凑存储参数。
不管是内存使用或者是性能，数据结构将产生很大的影响，下面是一些可以参考的最佳实践：
取代将数据存储为数千（或者数百万）独立的字符串，可以考虑使用哈希数据结构将相关数据进行分组。哈希表是非常有效率的，并且可以减少你的内存使用；
同时，哈希还更有益于细节抽象和代码可读。合适时候，使用list代替set。如果你不需要使用set特性，List在使用更少内存的情况下可以提供比set更快的速度。
Sorted sets是最昂贵的数据结构，不管是内存消耗还是基本操作的复杂性。如果你只是需要一个查询记录的途径，并不在意排序这样的属性，那么轻建议使用哈希表。
2)控制所有键名的长度
3)掌控储存在Redis中的所有键,不用的键值要及时删除
4)当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能以及最大的内存使用量。
5)如果需要使用持久化，根据是否可以容忍重启丢失部分数据在RDB与AOF之间选择其一，不要使用虚拟内存VM以及diskstore方式。
6)不要让你的Redis所在机器物理内存使用超过实际内存总量的3/5。


Reids的主从复制机制原理。
redis采用异步的形式复制数据到slave，从redis 2.8开始，slave会周期性地确认自己每次复制的数据量
1)一个master node可以连接多个slave node
2)slave node 也可以连接其他slave node
3)slave node复制数据时不会block master node
4)slave node 复制数据也不会block 自己的查询操作，它会用旧的数据对外提供服务，但复制完成后，需要删除旧的数据，加载新数据，这个时候会暂停对外服务
5)slave node主要用来进行横向扩容，扩容可以提高更高的读的吞吐量


Redis的线程模型是什么。
Redis 基于 Reactor 模式开发了自己的网络事件处理器：文件事件处理器。基于 select、epoll 实现IO多路复用程序来监听多个套接字。


如何看待缓存的使用（本地缓存，集中式缓存），简述本地缓存和集中式缓存和优缺点。 
Nginx+Redis/Memcached+Ehcache
Nginx常来做流量分发，同时nginx本身也有自己的缓存机制，可以用来缓存静态资源，让用户的请求直接走缓存并返回，从而减少流向服务器的流量。
对于部署多个nginx而言，如果不加入一些路由策略，那么可能导致每个nginx的缓存命中率很低，因此可以部署双层Nginx提升缓存命中率。
用户的请求，在nginx没有缓存相应数据，那么进入到 Redis 缓存中，Redis 可做到全量数据缓存，通过水平扩展能够提升高并发，高可用能力。
Ehcache jvm堆内存缓存，如果redis出现了大规模的宕机，导致nginx大量流量直接流向数据库，那么最后JVM缓存也可以处理部分请求，避免所有请求直接流向数据库。

一致性
进程内缓存：当使用进程内缓存时，缓存元素是特定应用程序实例本地的。然而许多中大型应用通常会做负载均衡，往往是多台机器跑同一个应用。在这种情况下，
很可能会构建出一个有多少应用实例就有多少缓存，每个缓存都有各自的状态，导致缓存不一致。
分布式缓存：虽然部署在由多个节点构成的集群上，但是会提供一个单一缓存的逻辑视图（以及状态）。多数情况下，分布式缓存中的对象将会存在于集群中的单
个节点。通过哈希算法，缓存引擎总是可以判断出某个键值对位于哪个特定节点。由于整个集群总是会有一个特定状态，所以不会存在缓存不一致情况。
备注
如果你需要缓存不变的对象，一致性将不是一个问题。在这种情况下，进程内缓存是一个更好的解决方案，因为它没有分布式缓存的管理开销。
如果你的应用部署在多个节点上，想要缓存可变的对象同时需要每次读都是一致的而不仅仅满足最终一致性，则应当采用分布式缓存。

开销
进程内缓存可能会影响垃圾回收进而影响系统性能。这将会由缓存大小以及对象逐出和过期的频率决定。
分布式缓存有两大主要开销会导致其慢于进程内缓存（但优于无缓存方案）：网络延迟和对象序列化。
备注
如果你试图寻求一个多节点部署情况下的强一致性缓存解决方案，采用分布式缓存。

可靠性
进程内缓存与应用程序使用同一堆空间，因此必须非常小心地决定缓存所能使用的内存上限。如果应用程序用光了内存，想要恢复并不容易。
分布式缓存作为多个节点的独立进程运行，因此单点故障并不会导致缓存失效。丢失的缓存元素将会在下一次缓存未命中时进入存活的节点。分布式缓存情况下，
缓存整体失效的最坏后果是降低系统性能，而不是导致系统整体故障。
备注
进程内缓存适用于较小且频率可预见的访问场景，尤其适用于不变对象。对于较大且不可预见的规模的访问，最好采用分布式缓存。

总结
对于不变对象的较小规模的、可预见次数的访问，进程内缓存是一个理想解决方案，性能上它优于分布式缓存。然而，对于要缓存的对象数量是未知的并且较大的
情况下，同时要求读一致性，分布式缓存是一个更好的解决方案，尽管进程内缓存可能具备与它相同的性能。


本地缓存在并发使用时的注意事项。
一个缓存如果失效，可能出现多个请求该数据的进程同时查询DB、同时设置缓存的情况。如果并发确实很大，会造成DB压力过大，还有缓存频繁更新的问题。
在某个请求发现缓存没有数据时，需要获取一个排它锁，由此请求查询数据库并更新缓存，完成后释放锁。在此请求操作的过程中，阻塞所有其它请求同一数据的请求，等这个更新请求完成后直接从缓存获取数据。


开源框架知识

简单讲讲tomcat结构，以及其类加载器流程，线程模型等。
Tomcat的核心组件就Connector和Container，一个Connector+一个Container（Engine）构成一个Service，Service就是对外提供服务的组件
BootStrap引导加载器，extension扩展加载器，system系统加载器，common加载器(负责加载/common目录的类库，这儿存放的类库可被tomcat以及所有的应用使用)
tomcat支持四种线程模型:BIO、NIO、APR和AIO


tomcat如何调优，涉及哪些参数 。
1）吞吐量  2）Responsetime  3）Cpuload  4）MemoryUsage
-server、-Xms和-Xmx设置成一样大、-Xmn合理设置新生代大小(Sun官方推荐配置为整个堆的3/8)、-Xss设置栈大小
Tomcat容器内优化：打开tomcat安装目录\conf\server.xml文件,可以设置一堆参数


讲讲Spring加载流程。
初始化环境—>加载配置文件—>实例化Bean—>调用Bean显示信息


Spring AOP的实现原理。
将与业务无关，却被业务模块共同调用的逻辑封装起来，
Spring提供了两种方式生成代理对象：JDKProxy和Cglib具体使用哪种方式生成由AopProxyFactory根据AdvisedSupport对象的配置来决定。


讲讲Spring事务的传播属性。
PROPAGATION_REQUIRED:如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入当前事务(都执行成功才提交，有一个失败就回滚)
PROPAGATION_REQUIRES_NEW:无论当前是否存在事务，都创建一个新事务(事务成败与否，不会影响其它事务)
PROPAGATION_NESTED:如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作(内层事务失败与否不会影响外层事务，外层事务回滚，内层事务也回滚)


Spring如何管理事务的。
PlatformTransactionManager：事务管理器，主要用于平台相关事务的管理。
TransacitonDefinition：事务定义信息，用来定义事务相关属性。
TransationStatus：事务具体运行状态，事务管理过程中，每个时间点事务的状态信息。


Spring怎么配置事务（具体说出一些关键的xml 元素）。
1）基于XML的事务配置  2）基于注解方式的事务配置(@Transactional)。
编程式事务使用TransactionTemplate或者直接使用底层的PlatformTransactionManager。
声明式事务是建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。
声明式事务管理要优于编程式事务管理，这正是spring倡导的非侵入式的开发方式。


说说你对Spring的理解，非单例注入的原理？它的生命周期？循环注入的原理，aop的实现原理，说说aop中的几个术语，它们是怎么相互工作的。
IOC和AOP框架
IOC控制反转：由spring来负责控制对象的生命周期和对象间的关系。
			所有的类都会在Spring中登记，Spring管理所有的对象，当某个具体类需要什么对象的时候，不需要自己创建对象，直接调用spring即可。
			最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫“依赖查找”（Dependency Lookup）。
DI依赖注入：在程序运行中，动态的向某个对象提供它所需要的其他对象。
		   spring使用java bean对象的set方法或者带参数的构造方法，在创建对象的过程中将其属性自动设置为设定值
           set方法注入、构造方法注入、静态工厂方法注入、实例工厂方法注入
AOP面向切面编程：将一个个对象某些类似的方面横向抽象成一个切面，对这个切面进行一些如权限验证，事务管理，记录日志等公共操作
生命周期：创建(实例化:分配内存空间、初始化:属性注入)-使用-销毁。IOC容器启动时，并没有初始化所有对象，只有调用getBean()才会触发bean的初始化操作。
循环注入：两个或多个Bean相互之间的持有对方，比如A引用B，B引用C，C引用A。
		 构造器循环依赖，无法解决，抛出BeanCurrentlyInCreationException
		 setter方法循环注入。


netty的线程模型，netty如何基于reactor模型上实现的。
多路复用IO，select、poll、epoll


为什么选择netty。
稳定，API使用简单，开发门槛低


什么是TCP粘包，拆包。解决方式是什么。
TCP粘包：socket读取时，读到了实际意义上的两个或多个数据包的内容，同时将其作为一个数据包进行处理。
TCP拆包：socket读取时，没有完整地读取一个数据包，只读取一部分。
解决方法：数据段定长，位数不足的空位补齐；
		 消息头+消息体，消息头中一般会包含消息体的长度、消息类型等信息；
		 特殊字符(比如回车符)作为消息数据的结尾，以实现消息数据的分段
		 通过复杂的应用层协议


netty的fashwheeltimer的用法，实现原理，是否出现过调用不够准时，怎么解决。
时间轮算法


netty的心跳处理在弱网下怎么办。
心跳机制:在长链接中双方没有数据交互的时候互相发送数据(可能是空包，也可能是特殊数据)，对方收到该数据之后也回复相应的数据用以确保双方都在线。
一般实现心跳机制由两种方式：TCP协议自带的心跳机制来实现；在应用层实现。
通常采用应用层自定义实现：Client启动一个定时器，不断发送心跳；Server收到心跳后，做出回应；Server启动一个定时器，判断Client是否存在，
					   这里做判断有两种方法：时间差和简单标识。


netty的通讯协议是什么样的。


springmvc用到的注解，作用是什么，原理。
DispatcherServlet前端控制器，HandlerMapping处理器映射，Controller，VierResolver视图解析器
SpringMVC运行原理：
1.客户端提交请求到DispatchServlet
2.DispatchServlet查询一个或多个HandleMapping，找到处理请求的Controller
3.DispatchServlet将请求交给Controller
4.Controller调用相应的xxxService方法，返回ModelAndView
5. DispatcherServlet查询一个或多个ViewResoler视图解析器，找到ModelAndView指定的视图
6.View视图将结果显示到客户端
常用注解：
@Controller 声明Action组件
@Service 声明Service组件 @Service("myMovieLister")
@Repository 声明Dao组件
@Component 泛指组件, 当不好归类时.
@RequestMapping("/menu") 请求映射
@Resource 用于注入，(j2ee提供的)默认按名称装配，@Resource(name="beanName")
@Autowired 用于注入，(srping提供的)默认按类型装配
@Transactional(rollbackFor={Exception.class})事务管理
@ResponseBody
@Scope("prototype") 设定bean的作用域


SSM 和 Springboot 的最大区别
1.Springboot 将原有的 xml 配置，简化为 java 注解
2.使用 IDE 可以很方便的搭建一个 springboot 项目，选择对应的 maven 依赖，简化Spring应用的初始搭建以及开发过程
3.springboot 有内置的 tomcat 服务器，可以 jar 形式启动一个服务,可以快速部署发布 web 服务
4.springboot 使用 starter 依赖自动完成 bean 配置，解决 bean 之间的冲突，并引入相关的 jar 包（这一点最重要）


springboot启动机制。
@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}

@SpringBootApplication详解：
@SpringBootConfiguration             // 继承了Configuration，表示当前是注解类
@EnableAutoConfiguration             // 开启springboot的注解功能，springboot的四大神器之一，其借助@import的帮助
@ComponentScan(excludeFilters = {    // 扫描路径设置（具体使用待确认）
public @interface SpringBootApplication {
...
}

虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：
@Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）
@EnableAutoConfiguration
@ComponentScan

@Configuration：使用注解方式
基于XML的配置形式是这样：
<bean id="mockService" class="..MockServiceImpl">         
    ...
</bean>
而基于JavaConfig的配置形式是这样的：
@Configuration
public class MockConfiguration{
    @Bean
    public MockService mockService(){
        return new MockServiceImpl();
    }
}

@ComponentScan：
自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，将这些bean定义加载到IoC容器中。

@EnableAutoConfiguration：
借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器


1、什么是 Spring Boot？
Spring Boot 是 Spring 开源组织下的子项目，是 Spring 组件一站式解决方案，主要是简化了使用 Spring 的难度，简省了繁重的配置，提供了各种启动器，开发者能快速上手。


2、为什么要用 Spring Boot？
Spring Boot 优点非常多，如：
独立运行
简化配置
自动配置
无代码生成和XML配置
应用监控
上手容易
...


3、Spring Boot 的核心配置文件有哪几个？它们的区别是什么？
Spring Boot 的核心配置文件是 application 和 bootstrap 配置文件。
application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置。
bootstrap 配置文件有以下几个应用场景：
使用 Spring Cloud Config 配置中心时，这时需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息；
一些固定的不能被覆盖的属性；
一些加密/解密的场景；


4、Spring Boot 的配置文件有哪几种格式？它们有什么区别？
.properties 和 .yml，它们的区别主要是书写格式不同。
.properties
app.user.name = javastack

.yml
app:
  user:
    name: javastack
另外，.yml 格式不支持 @PropertySource 注解导入配置。


5、Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？
启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：
@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。
@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。
@ComponentScan：Spring组件扫描。


6、开启 Spring Boot 特性有哪几种方式？
1）继承spring-boot-starter-parent项目
2）导入spring-boot-dependencies项目依赖


7、Spring Boot 需要独立的容器运行吗？
可以不需要，内置了 Tomcat/ Jetty 等容器。


8、运行 Spring Boot 有哪几种方式？
1）打包用命令或者放到容器中运行
2）用 Maven/ Gradle 插件运行
3）直接执行 main 方法运行


9、Spring Boot 自动配置原理是什么？
注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，首先它得是一个配置文件，其次根据类路径下是否有这个类去自动配置。


10、Spring Boot 的目录结构是怎样的？
cn
 +- javastack
     +- MyApplication.java
     |
     +- customer
     |   +- Customer.java
     |   +- CustomerController.java
     |   +- CustomerService.java
     |   +- CustomerRepository.java
     |
     +- order
         +- Order.java
         +- OrderController.java
         +- OrderService.java
         +- OrderRepository.java

这个目录结构是主流及推荐的做法，而在主入口类上加上 @SpringBootApplication 注解来开启 Spring Boot 的各项能力，如自动配置、组件扫描等。


11、你如何理解 Spring Boot 中的 Starters？
Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。
如你想使用 Spring JPA 访问数据库，只要加入 spring-boot-starter-data-jpa 启动器依赖就能使用了。Starters包含了许多项目中需要用到的依赖，
它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。


12、如何在 Spring Boot 启动的时候运行一些特定的代码？
可以实现接口 ApplicationRunner 或者 CommandLineRunner，这两个接口实现方式一样，它们都只提供了一个 run 方法。


13、Spring Boot 有哪几种读取配置的方式？
Spring Boot 可以通过 @PropertySource,@Value,@Environment, @ConfigurationProperties 来绑定变量。


14、Spring Boot 支持哪些日志框架？推荐和默认的日志框架是哪个？
Spring Boot 支持 Java Util Logging, Log4j2, Lockback 作为日志框架，如果你使用 Starters 启动器，Spring Boot 将使用 Logback 作为默认日志框架。


15、SpringBoot 实现热部署有哪几种方式？
主要有两种方式：
Spring Loaded
Spring-boot-devtools


16、你如何理解 Spring Boot 配置加载顺序？
在 Spring Boot 里面，可以使用以下几种方式来加载配置。
1）properties文件；
2）YAML文件；
3）系统环境变量；
4）命令行参数；
……


17、Spring Boot 如何定义多套不同环境配置？
提供多套配置文件，运行时指定具体的配置文件。如：
applcation.properties
application-dev.properties
application-test.properties
application-prod.properties


18、Spring Boot 可以兼容老 Spring 项目吗，如何做？
可以兼容，使用 @ImportResource 注解导入老 Spring 项目配置文件。


19、保护 Spring Boot 应用有哪些方法？
在生产中使用HTTPS
使用Snyk检查你的依赖关系
升级到最新版本
启用CSRF保护
使用内容安全策略防止XSS攻击
...


20、Spring Boot 2.X 有什么新特性？与 1.X 有什么区别？
配置变更
JDK 版本升级
第三方类库升级
响应式 Spring 编程支持
HTTP2.0 支持
配置属性绑定
...


架构设计与分布式

多人同时操作同一条数据，如何保证不出错
利用数据库层面的锁、事务、给数据加上一列last update time；分布式锁


2PC和3PC简述
分布式事务/分布式协议/分布式一致性算法
两阶段提交：分为准备阶段和提交阶段，提议的节点称为协调者，参与投票的节点称为参与者。
           准备阶段，协调者发起一个提议，分别询问各参与者是否接受；
           提交阶段，协调者根据参与者的反馈，提交或中止事务，如果参与者全部同意则提交，只要有一个参与者不同意就中止。
存在的问题：同步阻塞问题。所有参与的节点都是阻塞的，如果部分节点回应慢，会导致其它节点长时间锁定公共资源。
		   单点故障。协调者宕机会导致参与者长时间等待。
		   数据不一致。提交阶段，由于网络原因，只有部分参与者收到commit信息，导致部分参与者提交，部分参与者未提交。
		   协调者和参与者宕机。协调者发送完commit后宕机，唯一收到该信息的参与者也宕机了，那么即使通过选举协议重新选举出协调者，这条事务的状态也是未知的。
三阶段提交：CanCommit阶段  协调者向参与者发送CanCommit请求，询问是否可以执行事务提交操作。然后开始等待参与者的响应。
		   PreCommit阶段  发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。
						  事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。
						  响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。
						  假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断
		   doCommit阶段   发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。
						  事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。
						  响应反馈 事务提交完之后，向协调者发送Ack响应。
						  完成事务 协调者接收到所有参与者的ack响应之后，完成事务。
2PC和3PC区别：引入超时机制。同时在协调者和参与者中都引入超时机制。
			 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。


分布式集群下如何做到唯一序列号。
1.数据库自增长序列或字段：在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成，有单点故障的风险
2.UUID：全球唯一；没有排序，无法保证趋势递增；使用字符串存储，查询的效率比较低；存储空间大
3.Redis生成ID：利用Redis的原子操作 INCR和INCRBY。比如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5
4.Twitter的snowflake算法


设计一个秒杀系统，30分钟没付款就自动关闭交易。
前端：页面静态化、禁止重复提交(按钮点击后响应前置灰)
后端：扩展。对于用户的请求，映射到不同的数据库，减少单台数据库的压力。
     缓存。将参加秒杀的商品信息事先缓存到redis等缓存系统中，这样可以大大的提高系统的吞吐量，减少关系型数据库的读写压力。
     限流。在库存没有之后，将前端的秒杀入口关闭。
     削峰。将大量涌入的请求添加到消息中间件中。
如何抗住高并发：
配置静态页面；提前将静态页面刷新到cdn节点；将H5页面部署在公有云上，便于动态扩展；在提供秒杀业务功能的服务器上，需要进行限流和熔断，防止秒杀
业务影响其它正常服务的功能，比如使用hystrix，当流量超过限定阈值后，返回失败报文；服务降级，首页、购物车、订单查询、大数据等功能都会进行一定程
度的服务降级，以保证秒杀系统能得到系统最大支持。
如何防止超卖：
思路1：实时库存的扣减在缓存(比如redis)中进行，然后异步扣减数据库中的库存，保证缓存中和数据库中库存的最终一致性。
思路2：将要促销的商品数量以list的方式存入redis中，每当用户抢到一件促销商品则从队列中删除一个数据，确保商品不会超卖。


如何使用redis和zookeeper实现分布式锁？ 有什么区别优缺点，会有什么问题，分别适用什么场景。（如果知道redlock，讲讲算法实现，争议在哪里）
1.基于数据库表主键唯一做分布式锁
对请求信息进行hash运算,得到一个hash值,并以此作为主键保存到数据库中，保存成功之后,才进行正常的业务逻辑处理。
如果有多个相同请求同时提交请求，它们对请求信息的hash值是相同的，由于主键唯一性，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功
的那个线程获得了该方法的锁。当方法执行完毕之后，删除这条数据库记录即可释放锁。

2.基于表字段Version做分布式锁
为每个表设计一个Version字段，然后每次写sql都要带着Version字段。
-- 添加版本号控制字段
ALTER TABLE table ADD COLUMN version INT DEFAULT '0' NOT NULL AFTER t_bonus;

-- 线程1查询，当前left_count为1，则有记录，当前版本号为1234
select left_count, version from t_bonus where id = 10001 and left_count > 0

-- 线程2查询，当前left_count为1，有记录，当前版本号为1234
select left_count, version from t_bonus where id = 10001 and left_count > 0

-- 线程1,更新完成后当前的version为1235，update状态为1，更新成功
update t_bonus set version = 1235, left_count = left_count-1 where id = 10001 and version = 1234

-- 线程2,更新由于当前的version为1235，udpate状态为0，更新失败，再针对相关业务做异常处理
update t_bonus set version = 1235, left_count = left_count-1 where id = 10001 and version = 1234

3.基于数据库排他锁做分布式锁
使用 select for update，数据库会在查询过程中给行/表增加排他锁。我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，
可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。

4.基于Redis做分布式锁
4.1 基于Redis的 SETNX()、EXPIRE() 方法做分布式锁
setnx key value，该方法是原子的，若当前已经存在key，则设置key失败返回0，如果key不存在，则设置key成功返回1；
expire key seconds，设置key的过期时间；
步骤一、setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功
步骤二、expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。
步骤三、执行完业务代码后，可以通过 delete 命令删除 key。
存在的问题：setnx成功后、expire执行前，若服务器宕机，仍然可能会出现死锁

4.2 基于Redis的 SETNX()、GET()、GETSET()方法做分布式锁
getset key value，设置新值返回旧值；
步骤一、setnx(lockkey,当前时间+过期超时时间)，如果返回1，则获取锁成功，如果返回0，则没有获取锁，转2
步骤二、get(lockkey)获得oldExpireTime，若小于当前时间，说明锁已经过期，别的请求可以获取锁
步骤三、getset(lockkey,当前时间+过期超时时间)获得currentExpireTime
步骤四、比较oldExpireTime和currentExpireTime，若两者相等，说明成功获取到锁，若不相等，说明get和getset期间有别的请求获取到了锁
步骤五、在获取到所之后，当前线程可以开始业务处理，当执行完毕后，比较执行时间和锁过期超时时间，若小于超时时间，则执行del lockkey释放锁，若大于锁超时时间，则不需要进行锁处理

5.基于 RedLock 做分布式锁
它基于N个完全独立的Redis节点(通常情况下N可以设置成5)
步骤一、client获取当前时间t0
步骤二、使用4.2 的方法向N个节点申请锁，client需要设置访问接口超时时间(远小于锁超时时间)，比如锁自动释放的时间是 10s，那么接口超时大概设置
5-50ms。这样可以在有 redis 节点宕机后，访问该节点时能尽快超时，跳到下一个节点去申请锁。
步骤三、client通过当前时间t1减去t0，计算获得锁消耗的时间t2，如果t2小于锁超时时间并且client在超过半数的节点上获得锁，则认为锁获取成功
步骤四、如果client获取锁失败了，client会依次删除已经获取的节点锁。

6.基于 ZooKeeper 做分布式锁
zk 一般由多个节点构成（单数），采用zab一致性协议。因此可以将 zk 看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改而后才提供查询服务。
zk 的数据以目录树的形式，每个目录称为 znode， znode 中可存储数据（一般不超过 1M），还可以在其中增加子节点。
子节点有三种类型：序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。临时节点，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。
Watch 机制，client可以监控每个节点的变化，当发生变化会给 client 产生一个事件。
锁服务分两种，一个是保持独占，一个是控制时序。 
保持独占
步骤一、所有客户端都去创建/distribute_lock节点，创建成功则获得锁，用完删除自己创建的/distribute_lock节点。
控制时序
步骤一、所有客户端在预先存在的/distribute_lock节点下面创建临时顺序节点
步骤二、只有序号最小的可以拥有锁，如果这个节点序号不是最小则watch序号比本身小的前一个节点/序号最小的节点(公平锁/非公平锁)。等待watch事件到来后，再次判断是否序号最小。
步骤三、取锁成功则执行代码，最后释放锁(删除临时节点)。


分布式事务的原理，优缺点，如何使用分布式事务。
两阶段提交、三阶段提交、Paxos
优点是可以管理多机事务，拥有无限扩展性 缺点是易用性难，有延时风险


什么是一致性hash。
一致性Hash算法是对2^32取模，将整个哈希值空间顺时针组织成一个虚拟的圆环(0~2^32-1)；然后将服务器根据IP进行哈希，确定其在环上的位置。
接着分配数据到服务器：将数据key使用相同的函数计算哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其定位到的服务器。
容错性和可扩展性强
一致性Hash算法在服务器节点太少时，容易因为节点分部不均匀而造成数据倾斜，可以引入虚拟节点。


什么是restful，讲讲你理解的restful。
面向资源；url不包含动词：GET /zoos/ID/animals：列出某个指定动物园的所有动物
表述性状态转移。URI统一资源标识符，URL统一资源定位符
每一个URI代表一种资源；客户端通过四个HTTP动词(post增del删put改get查)，对服务器资源进行操作，实现"状态转化"。


如何设计一个良好的API。
明确职责；
单一性原则：一个接口只做一件事；
协议规范：采用 http/https/ftp；
路径规则：由于api获取的是一种资源，所以网址中尽量为名词，而非动词，比如/api/v1.0/Pruduct/2019；
http请求方式：get(获取)，post(新增)，put(修改)和delete(删除)
域名：域名分为主域名和专有域名，主域名适合api长期不变或变化较少的业务，专有域名是解决具体的专有业务的，比如主域名:www.baidu.com  百度文库 https://wenku.baidu.com/ 百度公益 http://gongyi.baidu.com
适度过滤信息：当记录数比较多时(如 SELECT * FROM TBName)，因适当添加一些条件对数据进行过滤，如TOP,分页,分组，排序和WHERE条件等，比如 ?limit=100：返回100条数据，?offset=101：从第101条数据开始返回
返回数据格式：采用json (1)失败情况(状态码、错误码和错误描述) (2)成功情况(状态码，标识id,数据对象)


如何设计建立和保持100w的长连接。
Netty NIO框架，增加xmx最大堆内存


解释什么是 MESI 协议(缓存一致性)
任何多核系统中的缓存都处于如下四种状态之中：
失效（Invalid）缓存段，要么已经不在缓存中，要么它的内容已经过时。为了达到一致性目的，这种状态的段将会被忽略。一旦缓存段被标记为失效，那效果就等同于它从来没被加载到缓存中。
共享（Shared）缓存段，它是和主内存内容保持一致的一份拷贝，在这种状态下的缓存段只能被读取，不能被写入。多组缓存可以同时拥有针对同一内存地址的共享缓存段，这就是名称的由来。
独占（Exclusive）缓存段，和S状态一样，也是和主内存内容保持一致的一份拷贝。区别在于，如果一个处理器持有了某个E状态的缓存段，那其他处理器就不能同时持有它，所以叫“独占”。这意味着，如果其他处理器原本也持有同一缓存段，那么它会马上变成“失效”状态。
已修改（Modified）缓存段，属于脏段，它们已经被所属的处理器修改了。如果一个段处于已修改状态，那么它在其他处理器缓存中的拷贝马上会变成失效状态，
这个规律和E状态一样。此外，已修改缓存段如果被丢弃或标记为失效，那么先要把它的内容回写到内存中——这和回写模式下常规的脏段处理方式一样。


说说你知道的几种HASH算法，简单的也可以。
HASH算法：MD4、MD5、SHA-1，应用：文件校验，数字签名、鉴权协议
常用的构造散列函数的方法：
直接寻址法：取关键字或关键字的某个线性函数值为散列地址
数字分析法：寻找冲突小的数字部分
平方取中法：取关键字平方后的中间几位作为散列地址
随机数法、除数取余法
解决冲突的办法：线性探查法、双散列函数法、链表法


什么是paxos算法， 什么是zab协议。
paxos：Proposer提案者、acceptor投票者、learner学习者。只有被提出propose的值才可能被最终选定chosen。只有一个值会被选定chosen。进程只会获知到已经确认被选定chosen的值。
zab：Zookeeper Atomic Broadcast Zookeeper原子广播协议，一种支持崩溃恢复和原子广播的协议，整个 Zookeeper 就是在这两个模式之间切换。
基于该协议，Zookeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间数据一致性。所有客户端写入数据都是写入到主进程(Leader)中，然后由Leader复制到备份进程(Follower)中，从而保证数据一致性。
消息广播:Zab协议的消息广播过程使用的是一个原子广播协议，类似一个 2PC。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务
Proposal，将其发送给所有 Follower ，然后如果超过半数Follower成功响应，则执行 commit 操作。
崩溃恢复: Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群中最大的事务编号ZXID，那么就能够保证这个新选举出来的 Leader 一定具有所有已经提交的提案。


一个在线文档系统，文档可以被编辑，如何防止多人同时对同一份文档进行编辑更新
点击编辑的时候，利用redis的setNX进行加锁，并expire设置过期时间；使用版本号进行控制


线上系统突然变得异常缓慢，你如何查找问题。
第一步
top命令，查看CPU、内存、磁盘、I/O、网络带宽哪个因素导致系统变慢
如果是cpu占用过高，查看占用cpu高的进程，jstack生成进程的栈信息，看是否发生频繁 Full GC，如果是，需要查看一下堆内存快照，看看是否有内存泄漏；
如果是磁盘占用过高，及时清理磁盘；如果是带宽占用过大，请找网络工程师。如果都不是走第二步。
第二步
检查应用服务器Tomcat的线程池配置是否合理，看一下请求排队是否严重，如果严重则需要重新设置合理的线程池。同样，检查一下数据库的连接池设置是否合理，
是否需要增大数据库连接池，同时检查一下是否有慢sql，如果有慢sql，则进行优化（优化方案是查看执行计划，设置合理的索引等）。
第三步
查看访问慢的服务的调用链，到底是因为调用哪个服务过慢，导致整体变慢，联系相关系统的负责人进行排查和解决。
第四部
检查web服务器的请求日志，看一下是否存在DDos攻击，如果有DDoS攻击，则将攻击者的IP添加到防火墙的黑名单里。


说说你平时用到的设计模式。
单例模式、抽象工厂、适配器模式、外观模式、观察者模式、装饰器模式、迭代器模式、策略模式、建造者模式
具体例子见java_study


Dubbo的原理，有看过源码么，数据怎么流转的，怎么实现集群，负载均衡，服务注册和发现，重试转发，快速失败的策略是怎样的 。
一次RPC请求的流程是什么。
自己实现过rpc么，原理可以简单讲讲。Rpc要解决什么问题。


编程中自己都怎么考虑一些设计原则的，比如开闭原则，以及在工作中的应用。
对扩展开放，对修改封闭


MVC模式，即常见的MVC框架。
spring、struts


如何实现负载均衡，有哪些算法可以实现。
轮询法：将请求按顺序依次分配到服务器上，达到请求分布的绝对平衡。适用于机器性能相同的场景
随机法：通过系统随机函数，根据后台服务器列表的大小值来随机选取其中一台进行访问。适用于机器性能相同的场景
随机轮询法：随机选择第一个节点，之后仍像轮询法一样，依次分配
源地址哈希法：客户端IP哈希值%服务端列表，IP相同、服务器列表不变，每次都将访问同一个列表，可以增加缓存命中率
加权轮询法：Nginx的默认算法。配置高的服务器分配高权重，配置低的服务器分配低权重，具体实现：每次选择权重最大节点，然后对其减1，如果所有服务器权重都为0，则恢复初始权重
加权随机法：依据权重随机选择服务器，权重大被选中的几率大
最小连接数法：根据服务器当前的连接情况，动态选取当前积压连接数最少的服务器来处理请求，尽可能提高服务器利用率，将负载合理的分流到每一台服务器
最小延迟法：请求服务器的往返延迟（RTT），动态地选择延迟最低的服务器处理当前请求


Zookeeper的用途，选举的原理是什么。
zk的用途：1.命名服务 2.配置管理 3.集群管理 4.分布式锁 5.队列管理	
命名服务：通过指定的名字来获取资源或者服务的地址。zk会在自己的文件系统上创建一个以路径为名称的节点，它可以指向提供服务的地址，远程对象等。
配置管理：将各个程序的配置全部放在zk的某个目录节点上，然后所有相关程序监听该节点，一旦配置信息发生变化，每个应用程序就会收到zk的通知。
集群管理：主要有两点，一个是机器退出和加入，一个是选举master。 
		 对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听该节点的子节点变化消息。一旦有机器挂掉，导致与zk断开连接，
		 其创建的临时目录节点会被删除，其他机器都会收到通知。新机器加入也是类似，所有机器收到通知：新兄弟目录加入。
		 对于第二点，可以让所有机器创建临时顺序目录节点，每次选取编号最小的机器作为master。
分布式锁：锁服务分两种，一个是保持独占，另一个是控制时序。 
		 对于第一类，我们将zk上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建/distribute_lock节点，最终成功创建的
		 那个客户端拥有这把锁，用完删除自己创建的distribute_lock 节点就释放了锁。
		 对于第二类，/distribute_lock节点已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除。
队列管理：一种是同步队列，当队列成员都聚齐时，这个队列才可用，否则一直等待。 在约定目录下创建临时目录节点，监听节点数目是否达到我们要求的数目。
		 一种是FIFO队列，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。

ZooKeeper是一个分布式应用程序协调服务，它是集群的管理者，监视着集群中各个节点的状态,根据节点提交的反馈进行下一步合理操作。
(1)文件系统
zk文件系统 每个子目录项如 NameService 都被称作为znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的
不同在于znode可以存储数据。 有四种类型的znode，持久化目录节点、持久化顺序目录节点(客户端与zookeeper断开连接后，该节点依旧存在，并且zk给该节点名称进行顺序编号)
临时目录节点和临时顺序目录节点。
(2)通知机制
客户端注册监听它关心的目录节点，当目录节点发生变化(数据改变、被删除、子目录节点增加删除)时，zookeeper会通知客户端。

选举过程
当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的
状态。Zk的选举算法有两种：一种是基于basic paxos实现，另外一种是基于fast paxos算法实现。系统默认的选举算法为fast paxos。


Zookeeper watch机制原理。
所有的Zookeeper读操作，包括getData()、getChildren()和exists()，都有一个开关，可以在操作的同时再设置一个watch。Watch是一个一次性触发器，
会在被设置watch的数据发生变化的时候，发送事件给设置watch的客户端(类似于Redis的Watch)。
Watch是异步发送的。但ZooKeeper保证了一个顺序：一个客户端在收到watch事件之前，一定不会看到它设置过watch的值变动。


请思考一个方案，实现分布式环境下的countDownLatch。
每个子任务在zk文件系统的指定目录下创建一个临时目录文件，每当子任务完成，删除自己创建的节点。主任务监听该目录，当该目录下没有子文件，主任务启动。


后台系统怎么防止请求重复提交。
如果是单体服务器,我们可以通过多线程的常规锁解决,但是目前大部分系统,采用了多机负载均衡。
后端解决办法：方式一：在服务器端，生成一个唯一的Token标识符，将它存入session，同时将它写入表单的隐藏字段中，然后将表单页面发给浏览器，用户
			        录入信息后点击提交，在服务器端，获取表单中隐藏字段的值，与session中的唯一标识符比较，相等说明是首次提交，处理本次请求，
			        然后将session中的唯一标识符移除。不相等说明是重复提交，不再处理。
			 方式二：基于数据库主键唯一性的分布式锁、Redis setnx分布式锁、Zookeeper分布式锁。

前端解决办法：Js防止表单重复提交。方式一：设置标志符，提交后置为false，后序即使点了按钮也不提交后台。
							   方式二：按钮置灰，不可再用。
			 Redirect重定向到"提交成功"页面。
			 使用Cookie处理，设置是否提交的键值对，若已提交，提示客户端已提交。


描述一个服务从发布到被消费的详细过程。
dubbo


讲讲你理解的服务治理。
服务治理指的是管理微服务。网关就是整个整体的守门人，日志采集，追踪工具，服务注册发现都是用来采集信息的，然后需要监控平台来展现这些采集的信息，
并进行监控和分析。最后根据分析的结果采取治理策略，有的服务快撑不住了要限流，有的服务坏了要熔断，并且还能够及时的调整这些服务的配置。

常用工具如下：
Eureka，这是一个用来注册服务的工具，通过简单的配置，在服务启动的时候就会自动注册到Eureka服务器上。
Hystrix，这是一个用来保护服务的熔断工具，虽然最近宣布已经停止维护更新了。
Zuul，这是一个用来对请求进行路由的服务网关工具，最近的zuul2采用了Netty实现了异步非阻塞编程模型。
Ribbon，这是一个用来分配请求的负载均衡工具
Feign，这是一个用来更方便调用其它服务的工具，也能进行负载均衡
Archaius，这是一个管理配置API的工具
Spring Cloud Config，用来对配置进行管理，可以把每个服务的配置放在远端服务器以方便进行配置修改
Spring Cloud Sleuth，Tracing采集工具包，对Zipkin，HTrace进行了封装
Spring Cloud Consul，封装了Consul操作，同样是用来进行服务注册发现的
Spring Cloud Zookeeper，封装了Zookeeper，也是用来进行服务注册发现的
Spring Cloud Gateway，给Spring MVC提供API网关功能的工具，里面也包含安全处理等特性
除了Spring Cloud和Netfix提供的这些工具以外，还有下面这些工具也经常在服务监控治理中被使用：
Dubbo，自称是一个高性能的Java RPC框架，但是其实广泛用于服务注册发现，提供三个核心能力：面向接口的远程方法调用，智能容错和负载均衡，服务注册发现。
logback，java日志框架，是log4j的升级版本
ElasticSearch，虽然是一个搜索引擎和分析框架，但因为提供很好的存储和查询性能，所以经常用于日志的采集和存储
Kibana，Elastic的可视化插件，可以配合Elastic使用可视化查询日志
logstash，Elastic的日志分析工具
grafna，时序性分析工具，提供漂亮的图形化界面
Promethues，强大系统监控和报警框架，提供多维度数据模型，灵活强大的查询语句，有多种可视化图形界面
Spring boot admin，用来管理Spring Boot应用的工具，提供可视化的用户界面
Zipkin，分布式追踪工具，用来采集程序的延时数据
Htrace，Apache的分布式追踪工具。
resilience4j，用来被Hystrix指定作为熔断的替代工具。

如果把功能相同的进行一下归类，会发现有这样几个主要功能：
服务注册发现：Eurake，Dobbo，Consul，ZooKeeper
服务配置：Spring Cloud Config，Archaius
服务熔断：Hystrix，resilience4j
网关：Zuul，Spring Cloud Gateway
负载均衡：Ribbon，Feign
追踪工具：Sleuth，Zipkin，Htrace
日志采集：logback，ElasticSearch
监控平台：Promethues，Kibana，grafna，Spring boot admin


如何做到接口的幂等性。
方法一、根据业务的操作和内容生成一个全局ID，在执行操作前先根据这个全局唯一ID是否存在，来判断这个操作是否已经执行。如果不存在则把全局ID，
	   存储到存储系统中，比如数据库、redis等。如果存在则表示该方法已经执行。
方法二、去重表，适用于业务有唯一标识的插入场景中，比如在支付场景中，订单ID可以作为唯一标识。我们就可以建一张去重表，并且把唯一标识作为唯一索引，
	   在我们实现时，把创建支付单据和写入去去重表，放在一个事务中，如果重复创建，数据库会抛出唯一约束异常，操作就会回滚。
方法三、多版本控制，适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个Version号，来做幂等


如何做限流策略，令牌桶和漏斗算法的使用场景。
高并发系统的三中保护机制：缓存、限流和降级。
缓存：缓存的目的是提升系统访问速度和增大系统处理容量。
降级：降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 
限流：通过对并发请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理。
常用的限流算法有令牌桶和和漏桶。
漏桶：把请求比作是水，水来了都先放进桶里，并以限定的速度出水，当水来得过猛而出水不够快时就会导致桶溢出，即拒绝服务。
令牌桶：系统以恒定的速率产生令牌，然后把令牌放到令牌桶中，令牌桶有一个容量，当令牌桶满了的时候，再向其中放令牌，那么多余的令牌会被丢弃。
	   当想要处理一个请求的时候，需要从令牌桶中取出一个令牌，如果此时令牌桶中没有令牌，那么则拒绝请求。
	   令牌桶不仅能够限制数据的平均传输速率，还能允许某种程度的突发传输。


什么叫数据一致性，你怎么理解数据一致性。
CAP理论，为了保证高可用和分区容忍性，会牺牲部分数据一致性。
强一致性： 要求无论更新操作是在哪一个副本执行，之后所有的读操作都要能获得最新的数据。
弱一致性：用户读到某一操作对系统特定数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
最终一致性：是弱一致性的一种特例，保证用户最终能够读取到某操作对系统特定数据的更新。
常用的实现数据一致性的技术：
1、Quorum系统NRW策略，N台服务器，R表示完成读操作最少需要读取的副本数，W表示完成写操作最少需要写入的副本数。只需要保证R+W>N，就可以保证强一致性。 
  当R=Q,W=Q(Q=N/2+1)时，系统在读写性能之间取得平衡，兼顾了性能和可用性。
2、两阶段提交算法、三阶段提交算法
3、分布式锁服务实现数据一致性，是在操作目标之前先获取操作许可，然后再执行操作，如果其他用户同时尝试操作该目标将被阻止，直到前一个用户释放许可后，
  其他用户才能够操作目标。	
  采用分布式锁实现多副本内容修改的一致性问题， 选择控制内容颗粒度实现锁服务。例如我们要保证一个文件的多个副本修改一致， 可以对整个文件设置一把锁，
  修改时申请锁，修改这个文件的多个副本，确保多个副本内容一致，修改完成后释放锁；也可以对文件分段，或者是文件中的单个字节设置锁，实现更细颗粒度的锁操作，减少冲突。
  常用的锁实现算法有 Lamport面包店算法：解决多个线程并发访问一个共享的单用户资源的互斥问题的算法。
  				   Paxos算法
  				   基于Version字段的乐观锁


分布式服务调用方，不依赖服务提供方的话，怎么处理服务方挂掉后，大量无效资源请求的浪费，如果只是服务提供方吞吐不高的时候该怎么做，如果服务挂了，那么一会儿重启，该怎么做到最小的资源浪费，流量半开的实现机制是什么。
dubbo的泛化调用怎么实现的，如果是你，你会怎么做。
远程调用会有超时现象，如果做到优雅的控制，JDK自带的超时机制有哪些，怎么实现的。


搜索

elasticsearch了解多少，说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段。elasticsearch的倒排索引是什么。
elasticsearch 索引数据多了怎么办，如何调优，部署。
elasticsearch是如何实现master选举的。
详细描述一下Elasticsearch索引文档的过程。
详细描述一下Elasticsearch搜索的过程。
Elasticsearch在部署时，对Linux的设置有哪些优化方法？
lucence内部结构是什么。


数据库知识

join和union的区别
union 并操作，会把两张表的结果合并，不保留重复；union all 保留重复
join 交操作，inner join 内连接，left join 左连接，right join 右连接，full join 全连接


数据库隔离级别有哪些，各自的含义是什么，MYSQL默认的隔离级别是是什么。
读未提交，读已提交/不可重复读，可重复读，串行化
mysql默认是可重复读


什么是幻读。
如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。
那么以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。


MYSQL有哪些存储引擎，各自优缺点。
myisam:拥有较高的插入，查询速度，但不支持事务,使用表级锁，并发性差,主机宕机后，MyISAM 表易损坏，灾难恢复性不佳 
innodb:5.5版本后Mysql的默认数据库，事务型数据库的首选引擎，支持ACID事务，支持行级锁定,灾难恢复性好


高并发下，如何做到安全的修改同一行数据。
使用悲观锁 悲观锁本质是当前只有一个线程执行操作，结束了唤醒其他线程进行处理。 
也可以缓存队列中锁定主键。
加锁分为显式加锁与隐式加锁，上面的写法是显式加锁。mysql在执行insert、update会自动加锁，mysql对select却不会加锁


乐观锁和悲观锁是什么，INNODB的标准行级锁有哪2种，解释其含义。
乐观锁:认为修改不会发生冲突，只有在提交事务的时候才去检查，如果反正冲突则回滚
悲观锁:认为修改会引起冲突，所以一定要获得排它锁之后才能进行操作
共享锁S和排它锁X,意向共享锁IS和意向排它锁IX


SQL优化的一般步骤是什么，怎么看执行计划，如何理解其中各个字段的含义。
show status 通过慢查询日志定位哪些是执行效率的sql语句
explain sql 显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句


数据库会死锁吗，举一个死锁的例子，mysql怎么解决死锁。
事务A先修改表1后修改表2，事务2先修改表2后修改表1
原因：
系统资源不足
进程运行推进的顺序不合适 
资源分配不当等
处理：
重启数据库；杀死抢资源的进程


Mysql的索引原理，索引的类型有哪些，如何创建合理的索引，索引如何优化。
最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a=1 and b=2 and c>3 and d=4
如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql查询优化器会调整到最优顺序。
尽量选择区分度高的列作为索引，尽量少重复
尽量的扩展索引，不要新建索引。


聚集索引和非聚集索引的区别。
聚簇索引就是索引和记录紧密在一起。 
非聚簇索引 索引文件和数据文件分开存放，索引文件的叶子只保存了数据所在的物理地址，需要根据地址查找相应的数据块


select for update 是什么含义，会锁表还是锁行或是其他。
被select for update选定的数据不能被其他事务修改或删除，但是可以被普通select。若where指定了主键，锁行，否则锁表。


InnoDB实现了以下两种类型的行锁：
共享锁(S)：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
排他锁(X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。
另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。
意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁(X)；
对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显示给记录集加共享锁或排他锁。
共享锁(S)：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。
排他锁(X)：SELECT * FROM table_name WHERE … FOR UPDATE。


数据库的ACID是什么。
A，atomic，原子性，要么都提交，要么都失败，不能一部分成功，一部分失败。 
C，consistent，一致性，事物开始及结束后，数据的一致性约束没有被破坏 
I，isolation，隔离性，并发事物间相互不影响，互不干扰。 
D，durability,持久性，已经提交的事物对数据库所做的更新必须永久保存。即便发生崩溃，也不能被回滚或数据丢失。


某个表有近千万数据，CRUD比较慢，如何优化。
1.sql vs nosql
  不一定必须要关系型数据库存储，如果可靠性要求不高，完全可以用非关系型数据库存储
2.优化结构、sql语句+索引
  合理设计表结构，甚至违反设计范式做到适当冗余(避免经常需要join)。
  优化语句，生产环境分析慢日志。
  合理设置索引。
3.缓存
  对于读多写少的数据可以引入Redis/Memcached缓存
4.复制及读写分离(做主从复制，读写分离)    
                   -> Slave2
  Master -> Slave1 -> Slave3 
 		           -> Slave4 
  master负责写操作，slave负责读操作，master和slave需要保持数据一致性。为了减少master压力，可以让slave1和mater同步数据，然后slave1与其余slave同步数据
5.切分 垂直切分(分库)  水平切分(分表)
  垂直切分保证业务的独立性，防止不同业务争抢资源，毕竟业务是有优先级的。
  水平切分主要用于解决单表过大，突破单机瓶颈，只有切分才能真正做到分配负载。


Mysql怎么优化table scan的。
避免在where子句中对字段进行is null判断 
应尽量避免在where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。 
避免在where 子句中使用or 来连接条件 
in 和not in 也要慎用 
Like查询（非左开头） 
使用NUM=@num参数这种 
where 子句中对字段进行表达式操作num/2=XX 
在where子句中对字段进行函数操作


如何写sql能够有效的使用到复合索引。
例1：SELECT c1, c2 FROM t WHERE c = 100 and d = 'xyz' ORDER BY b  
我们可以创建一个集过滤、排序、覆盖于一体的索引：（c，d，b，c1，c2）
例2：SELECT * FROM t WHERE c > 100 and b < 10 and d = 'xyz'  
创建索引（d，b）/索引（d，c）
(先过滤后排序)先执行=，其次执行 order by，(范围查询会终止索引查询)<、>、between放最后。


mysql中in 和exists 区别。
mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。大家都认为exists比in语句的效率要高，
这种说法其实是不准确的。这个是要区分环境的。
如果查询的两个表大小相当，那么用in和exists差别不大。 
A B 两表，A in B 如果B较小，in不错，如果B很大，使用exists
not in 和not exists如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。 
1.EXISTS只返回TRUE或FALSE，不会返回UNKNOWN。
2.IN当遇到包含NULL的情况，那么就会返回UNKNOWN。


数据库自增主键可能的问题。
自增主键会产生表锁；在分库分表时可能会生成重复主键


MVCC的含义，如何实现的。
多版本并发控制，只有在InnoDB引擎下存在为了实现事务的隔离性，通过版本号，避免同一数据在不同事务间的竞争，你可以把它当成基于多版本号的一种乐观锁
InnoDB在每行数据都增加两个隐藏字段，一个记录创建的版本号，一个记录删除的版本号。


你做过的项目里遇到分库分表了吗，怎么做的，有用到中间件么，比如sharding jdbc等,他们的原理知道么。
COBAR -> MYCAT -> DBproxy
Sharding-JDBC直接封装JDBC API，可以理解为增强版的JDBC驱动，用客户端直连数据库，以jar包形式提供服务，无proxy代理层，无需额外部署，
无其他依赖，DBA也无需改变原有的运维方式


数据冷热分离
热数据可以存放在redis，冷数据存放在mysql
每次优先查询热库，当查询条件未命中（结果集为空）/当查询条件部分命中时，查询冷库。 
查询和使用热数据时，将一段时间不再使用的热数据移到冷库。
查询冷库时，将本次查询的结果移到热库，附上最新查询日期。


MYSQL的主从延迟怎么解决。
master服务器负责写操作，多台slave服务器负责读操作，所以master和slave之间要保持数据一致性。
一主多从、多主一从、级联复制 
						-> Slave
				 Master -> Slave -> Slave -> Slave
				 		-> Slave -> Slave -> Slave
架构改进:
业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力
服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。
不同业务的mysql物理上放在不同机器，分散压力。
单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。
硬件改进:
花钱


数据库

一、基本概念
1.主键、外键、超键、候选键
超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
候选键：是最小超键，即没有冗余元素的超键。
主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。
外键：在一个表中存在的另一个表的主键称此表的外键。

2.为什么用自增列作为主键
如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引；

如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引；

如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。

数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，
因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页

如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不
为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、
分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

3.触发器的作用？
触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经
许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。

4.什么是存储过程？用什么来调用？
存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。

调用：

1）可以用一个命令对象来调用存储过程。

2）可以供外部程序调用，比如：java程序。

5.存储过程的优缺点？
优点：

1）存储过程是预编译过的，执行效率高。

2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。

3）安全性高，执行存储过程需要有一定权限的用户。

4）存储过程可以重复使用，可减少数据库开发人员的工作量。

缺点：移植性差

6.存储过程与函数的区别


7.什么叫视图？游标是什么？
视图：

是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改会影响基本表。它使得我们获取数据更容易，相比多表查询。

游标：

是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

8.视图的优缺点
优点：
对数据库的访问，因为视图可以有选择性的选取数据库里的一部分。
用户通过简单的查询可以从复杂查询中得到结果。
维护数据的独立性，试图可从多个表检索数据。
对于相同的数据可产生不同的视图。

缺点：

性能：查询视图时，必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，那么就无法更改数据

9.drop、truncate、 delete区别
最基本：
drop直接删掉表。
truncate删除表中数据，再插入时自增长id又从1开始。
delete删除表中数据，可以加where字句。
（1） DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。
	 TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。

（2） 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，而DELETE操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。

（3） 一般而言，drop > truncate > delete

（4） 应用范围。TRUNCATE 只能对TABLE；DELETE可以是table和view

（5） TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。

（6） truncate与不带where的delete ：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束(constrain),
	  触发器(trigger)索引(index);依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。

（7） delete语句为DML(data maintain Language),这个操作会被放到 rollback segment中,事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。

（8） truncate、drop是DLL(data define language),操作立即生效，原数据不放到 rollback segment中，不能回滚。

（9） 在没有备份情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用delete且注意结合where来约束影响范围。回滚段要足够大。
	 要删除表用drop;若想保留表而将表中数据删除，如果于事务无关，用truncate即可实现。如果和事务有关，或老师想触发trigger,还是用delete。

（10）Truncate table 表名 速度快,而且效率高,因为:?truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。
	 但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。
	 TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。

（11） TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 DROP TABLE 语句。

（12） 对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。

10.什么是临时表，临时表什么时候删除?
临时表可以手动删除：
DROP TEMPORARY TABLE IF EXISTS temp_tb;

临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。因此在不同的连接中可以创建同名的临时表，并且操作属于本连接的临时表。
创建临时表的语法与创建表语法类似，不同之处是增加关键字TEMPORARY，

如：

CREATE TEMPORARY TABLE tmp_table (

NAME VARCHAR (10) NOT NULL,

time date NOT NULL
);

select * from tmp_table;

11.非关系型数据库和关系型数据库区别，优势比较?
非关系型数据库的优势：

性能：NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。
可扩展性：同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
关系型数据库的优势：

复杂查询：可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。
事务支持：使得对于安全性能很高的数据访问要求得以实现。
其他：

1.对于这两类数据库，对方的优势就是自己的弱势，反之亦然。

2.NOSQL数据库慢慢开始具备SQL数据库的一些复杂查询功能，比如MongoDB。

3.对于事务的支持也可以用一些系统级的原子操作来实现例如乐观锁之类的方法来曲线救国，比如Redis set nx。

12.数据库范式，根据某个场景设计数据表?
第一范式:(确保每列保持原子性)所有字段值都是不可分解的原子值。

第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。
第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。
但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。

第二范式:(确保表中的每列都和主键相关)在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。
也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。
比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。

第三范式:(确保每列都和主键列直接相关,而不是间接相关) 数据表中的每一列数据都和主键直接相关，而不能间接相关。

第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。
比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。

BCNF:符合3NF，并且，主属性不依赖于主属性。

若关系模式属于第二范式，且每个属性都不传递依赖于键码，则R属于BC范式。
通常BC范式的条件有多种等价的表述：每个非平凡依赖的左边必须包含键码；每个决定因素必须包含键码。
BC范式既检查非主属性，又检查主属性。当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。
还可以这么说：若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式。
一般，一个数据库设计符合3NF或BCNF就可以了。

第四范式:要求把同一表内的多对多关系删除。

第五范式:从最终结构重新建立原始结构。

13.什么是 内连接、外连接、交叉连接、笛卡尔积等?
内连接: 只连接匹配的行

左外连接: 包含左边表的全部行（不管右边的表中是否存在与它们匹配的行），以及右边表中全部匹配的行

右外连接: 包含右边表的全部行（不管左边的表中是否存在与它们匹配的行），以及左边表中全部匹配的行

例如1：
SELECT a.,b. FROM luntan LEFT JOIN usertable as b ON a.username=b.username

例如2：
SELECT a.,b. FROM city as a FULL OUTER JOIN user as b ON a.username=b.username

全外连接: 包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行。

交叉连接: 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配

例如：
SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type


14.varchar和char的使用场景?
1.char的长度是不可变的，而varchar的长度是可变的。

定义一个char[10]和varchar[10]。
如果存进去的是‘csdn’,那么char所占的长度依然为10，除了字符‘csdn’外，后面跟六个空格，varchar就立马把长度变为4了，取数据的时候，char类型的要用trim()去掉多余的空格，而varchar是不需要的。

2.char的存取数度还是要比varchar要快得多，因为其长度固定，方便程序的存储与查找。
char也为此付出的是空间的代价，因为其长度固定，所以难免会有多余的空格占位符占据空间，可谓是以空间换取时间效率。
varchar是以空间效率为首位。

3.char的存储方式是：对英文字符（ASCII）占用1个字节，对一个汉字占用两个字节。
varchar的存储方式是：对每个英文字符占用2个字节，汉字也占用2个字节。

4.两者的存储数据都非unicode的字符数据。

15.SQL语言分类
SQL语言共分为四大类：

数据查询语言DQL
数据操纵语言DML
数据定义语言DDL
数据控制语言DCL。
1. 数据查询语言DQL

数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：

SELECT
FROM
WHERE

2 .数据操纵语言DML

数据操纵语言DML主要有三种形式：
 插入：INSERT
 更新：UPDATE
 删除：DELETE

3. 数据定义语言DDL

数据定义语言DDL用来创建数据库中的各种对象-----表、视图、索引、同义词、聚簇等如：
CREATE TABLE/VIEW/INDEX/SYN/CLUSTER

表 视图 索引 同义词 簇

DDL操作是隐性提交的！不能rollback

4. 数据控制语言DCL

数据控制语言DCL用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等。如：
 GRANT：授权。
 
 ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点。回滚---ROLLBACK；回滚命令使数据库状态回到上次最后提交的状态。其格式为：
SQL>ROLLBACK;

 COMMIT [WORK]：提交。

在数据库的插入、删除和修改操作时，只有当事务在提交到数据
库时才算完成。在事务提交前，只有操作数据库的这个人才能有权看
到所做的事情，别人只有在最后提交完成后才可以看到。
提交数据有三种类型：显式提交、隐式提交及自动提交。下面分
别说明这三种类型。

(1) 显式提交
用COMMIT命令直接完成的提交为显式提交。其格式为：
SQL>COMMIT；

(2) 隐式提交
用SQL命令间接完成的提交为隐式提交。这些命令是：
ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，
EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。

(3) 自动提交
若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，
系统将自动进行提交，这就是自动提交。其格式为：
SQL>SET AUTOCOMMIT ON；


16.like %和-的区别
通配符的分类:

%百分号通配符:表示任何字符出现任意次数(可以是0次).

**_下划线通配符:**表示只能匹配单个字符,不能多也不能少,就是一个字符.

like操作符: LIKE作用是指示mysql后面的搜索模式是利用通配符而不是直接相等匹配进行比较.

注意: 如果在使用like操作符时,后面的没有使用通用匹配符效果是和=一致的,SELECT * FROM products WHERE products.prod_name like '1000';
只能匹配的结果为1000,而不能匹配像JetPack 1000这样的结果.

%通配符使用: 匹配以"yves"开头的记录:(包括记录"yves") SELECT FROM products WHERE products.prod_name like 'yves%';
匹配包含"yves"的记录(包括记录"yves") SELECT FROM products WHERE products.prod_name like '%yves%';
匹配以"yves"结尾的记录(包括记录"yves",不包括记录"yves ",也就是yves后面有空格的记录,这里需要注意) SELECT * FROM products WHERE products.prod_name like '%yves';

_通配符使用: SELECT *FROM products WHERE products.prod_name like '_yves'; 匹配结果为: 像"yyves"这样记录.
SELECT* FROM products WHERE products.prodname like 'yves_'; 匹配结果为: 像"yvesHe"这样的记录.(一个下划线只能匹配一个字符,不能多也不能少)

注意事项:
注意大小写,在使用模糊匹配时,也就是匹配文本时,mysql是可能区分大小的,也可能是不区分大小写的,这个结果是取决于用户对MySQL的配置方式.如果是区分大小写,那么像YvesHe这样记录是不能被"yves__"这样的匹配条件匹配的.
注意尾部空格,"%yves"是不能匹配"heyves "这样的记录的.
注意NULL,%通配符可以匹配任意字符,但是不能匹配NULL,也就是说SELECT * FROM products WHERE products.prod_name like '%';是匹配不到products.prod_name为NULL的的记录.

技巧与建议:
正如所见， MySQL的通配符很有用。但这种功能是有代价的：通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长。这里给出一些使用通配符要记住的技巧。
不要过度使用通配符。如果其他操作符能达到相同的目的，应该 使用其他操作符。
在确实需要使用通配符时，除非绝对有必要，否则不要把它们用 在搜索模式的开始处。把通配符置于搜索模式的开始处，搜索起 来是最慢的。
仔细注意通配符的位置。如果放错地方，可能不会返回想要的数.


**17.count(*)、count(1)、count(column)的区别**
count(*)对行的数目进行计算,包含NULL

count(column)对特定的列的值具有的行数进行计算,不包含NULL值。

count()还有一种使用方式,count(1)这个用法和count(*)的结果是一样的。

性能问题:

1.任何情况下SELECT COUNT(*) FROM tablename是最优选择;

2.尽量减少SELECT COUNT(*) FROM tablename WHERE COL = ‘value’ 这种查询;

3.杜绝SELECT COUNT(COL) FROM tablename WHERE COL2 = ‘value’ 的出现。

如果表没有主键,那么count(1)比count(*)快。

如果有主键,那么count(主键,联合主键)比count(*)快。

如果表只有一个字段,count(*)最快。

count(1)跟count(主键)一样,只扫描主键。count(*)跟count(非主键)一样,扫描整个表。明显前者更快一些。

18.最左前缀原则
多列索引：

ALTER TABLE people ADD INDEX lname_fname_age (lame,fname,age);

为了提高搜索效率，我们需要考虑运用多列索引,由于索引文件以B－Tree格式保存，所以我们不用扫描任何记录，即可得到最终结果。

注：在mysql中执行查询时，只能使用一个索引，如果我们在lname,fname,age上分别建索引,执行查询时，只能使用一个索引，mysql会选择一个最严格(获得结果集记录数最少)的索引。

最左前缀原则：顾名思义，就是最左优先，上例中我们创建了lname_fname_age多列索引,相当于创建了(lname)单列索引，(lname,fname)组合索引以及(lname,fname,age)组合索引。

二、索引
1.什么是索引？
何为索引：

数据库索引，是数据库管理系统中一个排序的数据结构，索引的实现通常使用B树及其变种B+树。

在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。

2.索引的作用？它的优点缺点是什么？
索引作用：

协助快速查询、更新数据库表中数据。

为表设置索引要付出代价的：

一是增加了数据库的存储空间
二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。

3.索引的优缺点？
创建索引可以大大提高系统的性能（优点）：

1.通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。

2.可以大大加快数据的检索速度，这也是创建索引的最主要的原因。

3.可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。

4.在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。

5.通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

增加索引也有许多不利的方面(缺点)：

1.创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

2.索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。

3.当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。

4.哪些列适合建立索引、哪些不适合建索引？
索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。

一般来说，应该在这些列上创建索引：

（1）在经常需要搜索的列上，可以加快搜索的速度；

（2）在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；

（3）在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；

（4）在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；

（5）在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；

（6）在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。

对于有些列不应该创建索引：

（1）对于那些在查询中很少使用或者参考的列不应该创建索引。

这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。

（2）对于那些只有很少数据值的列也不应该增加索引。

这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。

（3）对于那些定义为text, image和bit数据类型的列不应该增加索引。

这是因为，这些列的数据量要么相当大，要么取值很少。

(4)当修改性能远远大于检索性能时，不应该创建索引。

这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。

5.什么样的字段适合建索引
唯一、不为空、经常被查询的字段

6.MySQL B+Tree索引和Hash索引的区别?
Hash索引和B+树索引的特点：

Hash索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位;

B+树索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问;

为什么不都用Hash索引而使用B+树索引？

Hash索引仅仅能满足"=","IN"和""查询，不能使用范围查询,因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样；

Hash索引无法被用来避免数据的排序操作，因为Hash值的大小关系并不一定和Hash运算前的键值完全一样；

Hash索引不能利用部分索引键查询，对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用；

Hash索引在任何时候都不能避免表扫描，由于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要回表查询数据；

Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B+树索引高。

补充：

1.MySQL中，只有HEAP/MEMORY引擎才显示支持Hash索引。

2.常用的InnoDB引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况，如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希
索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引），通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。

B+树索引和哈希索引的明显区别是：

3.如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；

4.如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
同理，哈希索引没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；

5.哈希索引也不支持多列联合索引的最左匹配规则；

6.B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

7.在大多数场景下，都会有范围查询、排序、分组等查询特征，用B+树索引就可以了。

7.B树和B+树的区别
B树，每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为nul，叶子结点不包含任何关键字信息。

B+树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息)

8.为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？
1.B+的磁盘读写代价更低

B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。

2.B+tree的查询效率更加稳定

由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

9.聚集索引和非聚集索引(二级索引)区别?
聚合索引(clustered index):

聚集索引表记录的排列顺序和索引的排列顺序一致，所以查询效率快，只要找到第一个索引值记录，其余就连续性的记录在物理也一样连续存放。聚集索引对应的缺点就是修改慢，因为为了保证表中记录的物理和索引顺序一致，在记录插入的时候，会对数据页重新排序。
聚集索引类似于新华字典中用拼音去查找汉字，拼音检索表于书记顺序都是按照a~z排列的，就像相同的逻辑顺序于物理顺序一样，当你需要查找a,ai两个读音的字，或是想一次寻找多个傻(sha)的同音字时，也许向后翻几页，或紧接着下一行就得到结果了。

非聚合索引(nonclustered index):

非聚集索引指定了表中记录的逻辑顺序，但是记录的物理和索引不一定一致，两种索引都采用B+树结构，非聚集索引的叶子层并不和实际数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针方式。非聚集索引层次多，不会造成数据重排。
非聚集索引类似在新华字典上通过偏旁部首来查询汉字，检索表也许是按照横、竖、撇来排列的，但是由于正文中是a~z的拼音顺序，所以就类似于逻辑地址于物理地址的不对应。同时适用的情况就在于分组，大数目的不同值，频繁更新的列中，这些情况即不适合聚集索引。

根本区别：

聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。

三、事务
1.什么是事务？
事务是对数据库中一系列操作进行统一的提交或者回滚操作，主要用来保证数据的完整性和一致性。

2.事务四大特性（ACID）原子性、一致性、隔离性、持久性?
原子性（Atomicity）:
原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

一致性（Consistency）:
事务开始前和结束后，数据库的完整性约束没有被破坏。比如A向B转账，不可能A扣了钱，B却没收到。

隔离性（Isolation）:
隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。

持久性（Durability）:
持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

3.事务的并发?事务隔离级别，每个级别会引发什么问题，MySQL默认是哪个级别?
从理论上来说, 事务应该彼此完全隔离, 以避免并发事务所导致的问题，然而, 那样会对性能产生极大的影响, 因为事务必须按顺序运行， 在实际开发中, 为了提升性能, 事务会以较低的隔离级别运行， 事务的隔离级别可以通过隔离事务属性指定。
事务的并发问题

1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致。

3、幻读：幻读解决了不重复读，保证了同一个事务里，查询的结果都是事务开始时的状态（一致性）。

例如：事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作 这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。 
而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有跟没有修改一样，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。


事务的隔离级别

读未提交：另一个事务修改了数据，但尚未提交，而本事务中的SELECT会读到这些未被提交的数据脏读

不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致。

可重复读：在同一个事务里，SELECT的结果是事务开始时时间点的状态，因此，同样的SELECT操作读到的结果会是一致的。但是，会有幻读现象

串行化：最高的隔离级别，在这个隔离级别下，不会产生任何异常。并发的事务，就像事务是在一个个按照顺序执行一样

特别注意：

MySQL默认的事务隔离级别为repeatable-read

MySQL 支持 4 中事务隔离级别.

事务的隔离级别要得到底层数据库引擎的支持, 而不是应用程序或者框架的支持.

Oracle 支持的 2 种事务隔离级别：READ_COMMITED , SERIALIZABLE

SQL规范所规定的标准，不同的数据库具体的实现可能会有些差异

MySQL中默认事务隔离级别是“可重复读”时并不会锁住读取到的行

事务隔离级别：未提交读时，写数据只会锁住相应的行。

事务隔离级别为：可重复读时，写数据会锁住整张表。

事务隔离级别为：串行化时，读写数据都会锁住整张表。

隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大，鱼和熊掌不可兼得啊。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed，它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。

4.事务传播行为
1.PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。

2.PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。

3.PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。

4.PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。

5.PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

6.PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。

7.PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

最常用的三种传播行为：
REQUIRED：外层调用方法和内层被调用方法，有异常一起回滚，没问题一起提交。（共用一个事务）
REQUIRES_NEW：内层被调用方法回滚与否，不会影响外层调用方法。而外层调用方法出异常回滚，也不会回滚内层被调用方法（两个独立的事务）
NESTED：内层被调用方法回滚与否，不会影响外层调用方法。而外层调用方法出异常回滚，也会回滚内层被调用方法（嵌套事务）


5.嵌套事务
什么是嵌套事务？

嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点就在于那个save point。

如果子事务回滚，会发生什么？

父事务会回滚到进入子事务前建立的save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。

如果父事务回滚，会发生什么？

父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理。那么：

事务的提交，是什么情况？

是父事务先提交，然后子事务提交，还是子事务先提交，父事务再提交？答案是第二种情况，还是那句话，子事务是父事务的一部分，由父事务统一提交。


四、存储引擎
1.MySQL常见的三种存储引擎（InnoDB、MyISAM、MEMORY）的区别?
两种存储引擎的大致区别表现在：

1.InnoDB支持事务，MyISAM不支持， 这一点是非常之重要。事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。

2.MyISAM适合查询以及插入为主的应用。

3.InnoDB适合频繁修改以及涉及到安全性较高的应用。

4.InnoDB支持外键，MyISAM不支持。

5.从MySQL5.5.5以后，InnoDB是默认引擎。

6.InnoDB不支持FULLTEXT类型的索引。

7.InnoDB中不保存表的行数，如select count() from table时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时MyISAM也需要扫描整个表。

8.对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引。

9.DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除，效率非常慢。MyISAM则会重建表。

10.InnoDB支持行锁（某些情况下还是锁整表，如 update table set a=1 where user like '%lee%'。

2.MySQL存储引擎MyISAM与InnoDB如何选择
MySQL有多种存储引擎，每种存储引擎有各自的优缺点，可以择优选择使用：MyISAM、InnoDB、MERGE、MEMORY(HEAP)、BDB(BerkeleyDB)、EXAMPLE、FEDERATED、ARCHIVE、CSV、BLACKHOLE。

虽然MySQL里的存储引擎不只是MyISAM与InnoDB这两个，但常用的就是两个。
关于MySQL数据库提供的两种存储引擎，MyISAM与InnoDB选择使用：

1.INNODB会支持一些关系数据库的高级功能，如事务功能和行级锁，MyISAM不支持。
2.MyISAM的性能更优，占用的存储空间少，所以，选择何种存储引擎，视具体应用而定。
如果你的应用程序一定要使用事务，毫无疑问你要选择INNODB引擎。但要注意，INNODB的行级锁是有条件的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！比如DELETE FROM mytable这样的删除语句。

如果你的应用程序对查询性能要求较高，就要使用MyISAM了。MyISAM索引和数据是分开的，而且其索引是压缩的，可以更好地利用内存。所以它的查询性能明显优于INNODB。压缩后的索引也能节约一些磁盘空间。MyISAM拥有全文索引的功能，这可以极大地优化LIKE查询的效率。

有人说MyISAM只能用于小型应用，其实这只是一种偏见。如果数据量比较大，这是需要通过升级架构来解决，比如分表分库，而不是单纯地依赖存储引擎。

现在一般都是选用innodb了，主要是MyISAM的全表锁，读写串行问题，并发效率锁表，效率低，MyISAM对于读写密集型应用一般是不会去选用的。
MEMORY存储引擎

MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。这些特性与前面的两个很不同。
每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。

MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。

注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的。

3.MySQL的MyISAM与InnoDB两种存储引擎在，事务、锁级别，各自的适用场景?
事务处理上方面

MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。

InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。

锁级别

MyISAM：只支持表级锁，用户在操作MyISAM表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。

InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。


五、优化
1.查询语句不同元素（where、jion、limit、group by、having等等）执行先后顺序?
1.查询中用到的关键词主要包含六个，并且他们的顺序依次为 select--from--where--group by--having--order by
其中select和from是必须的，其他关键词是可选的，这六个关键词的执行顺序 与sql语句的书写顺序并不是一样的，而是按照下面的顺序来执行

from:需要从哪个数据表检索数据

where:过滤表中数据的条件

group by:如何将上面过滤出的数据分组

having:对上面已经分组的数据进行过滤的条件

select:查看结果集中的哪个列，或列的计算结果

order by :按照什么样的顺序来查看返回的数据

2.from后面的表关联，是自右向左解析 而where条件的解析顺序是自下而上的。
也就是说，在写SQL语句的时候，尽量把数据量小的表放在最右边来进行关联（用小表去匹配大表），而把能筛选出小量数据的条件放在where语句的最左边 （用小表去匹配大表）


2.使用explain优化sql和索引?
对于复杂、效率低的sql语句，我们通常是使用explain sql 来分析sql语句，这个语句可以打印出，语句的执行。这样方便我们分析，进行优化

table：显示这一行的数据是关于哪张表的

type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL

all:full table scan ;MySQL将遍历全表以找到匹配的行；

index: index scan; index 和 all的区别在于index类型只遍历索引；

range：索引范围扫描，对索引的扫描开始于某一点，返回匹配值的行，常见与between ，等查询；

ref：非唯一性索引扫描，返回匹配某个单独值的所有行，常见于使用非唯一索引即唯一索引的非唯一前缀进行查找；

eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常用于主键或者唯一索引扫描；

const，system：当MySQL对某查询某部分进行优化，并转为一个常量时，使用这些访问类型。如果将主键置于where列表中，MySQL就能将该查询转化为一个常量。

possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句

key： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MySQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MySQL忽略索引

key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好

ref：显示索引的哪一列被使用了，如果可能的话，是一个常数

rows：MySQL认为必须检查的用来返回请求数据的行数

Extra：关于MySQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MySQL根本不能使用索引，结果是检索会很慢。

3.MySQL慢查询怎么解决?
slow_query_log 慢查询开启状态。

slow_query_log_file 慢查询日志存放的位置（这个目录需要MySQL的运行帐号的可写权限，一般设置为MySQL的数据存放目录）。

long_query_time 查询超过多少秒才记录。


六、数据库锁
1.mysql都有什么锁，死锁判定原理和具体场景，死锁怎么解决?
MySQL有三种锁的级别：页级、表级、行级。

表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。
行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。
页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般
什么情况下会造成死锁?
什么是死锁？

死锁: 是指两个或两个以上的进程在执行过程中。因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程。

表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB。

死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。

那么对应的解决死锁问题的关键就是：让不同的session加锁有次序。

死锁的解决办法?

1.查出的线程杀死 kill
SELECT trx_MySQL_thread_id FROM information_schema.INNODB_TRX;

2.设置锁的超时时间
Innodb 行锁的等待时间，单位秒。可在会话级别设置，RDS 实例该参数的默认值为 50（秒）。

生产环境不推荐使用过大的 innodb_lock_wait_timeout参数值
该参数支持在会话级别修改，方便应用在会话级别单独设置某些特殊操作的行锁等待超时时间，如下：
set innodb_lock_wait_timeout=1000; —设置当前会话 Innodb 行锁等待超时时间，单位秒。

3.指定获取锁的顺序

2.有哪些锁（乐观锁悲观锁），select 时怎么加排它锁?
悲观锁（Pessimistic Lock）:
悲观锁特点:先获取锁，再进行业务操作。
即"悲观"的认为获取锁是非常有可能失败的，因此要先确保获取锁成功再进行业务操作。通常所说的“一锁二查三更新”即指的是使用悲观锁。
悲观锁依靠数据库的锁机制实现，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，
因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。
补充：
不同的数据库对select for update的实现和支持都是有所区别的，
oracle支持select for update no wait，表示如果拿不到锁立刻报错，而不是等待，MySQL就没有no wait这个选项。
MySQL还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在MySQL中用悲观锁务必要确定走了索引，而不是全表扫描。

乐观锁（Optimistic Lock）:
1.乐观锁，也叫乐观并发控制，它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。
在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，那么当前正在提交的事务会进行回滚。
2.乐观锁的特点先进行业务操作，不到万不得已不去拿锁。即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。
乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。
3.一般的做法是在需要锁的数据上增加一个版本号，或者时间戳，
实现方式举例如下：
大多数基于数据版本（Version）记录机制实现。
SELECT data AS old_data, version AS old_version FROM …;
根据获取的数据进行业务操作，得到new_data和new_version
UPDATE SET data = new_data, version = new_version WHERE version = old_version
if (updated row > 0) {

// 乐观锁获取成功，操作完成

} else {

// 乐观锁获取失败，回滚并重试

}

拓展：ORM框架中悲观锁乐观锁的应用
1.Hibernate的悲观锁：
String hqlStr ="from TUser as user where user.name=Max";  
Query query = session.createQuery(hqlStr);  
query.setLockMode("user",LockMode.UPGRADE); //加锁  
List userList = query.list();//执行查询，获取数据  

2.Hibernate的乐观锁
通过class描述符的optimistic-lock属性结合version描述符指定。

注意：
乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能
乐观锁还适用于一些比较特殊的场景，例如在业务操作过程中无法和数据库保持连接等悲观锁无法适用的地方。

总结：
悲观锁和乐观锁是数据库用来保证数据并发安全防止更新丢失的两种方法，例子在select ... for update前加个事务就可以防止更新丢失。悲观锁和乐观锁大部分场景下差异不大，一些独特场景下有一些差别，一般我们可以从如下几个方面来判断。
响应速度： 如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁。
冲突频率： 如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大。
重试代价： 如果重试代价大，建议采用悲观锁。


七、其他
1.数据库的主从复制
主从复制的几种方式:
同步复制:
所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,...,slave-n完成后才能返回。 这样，显然不可取，也不是MySQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。

异步复制:
如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心,MySQL的默认设置。

半同步复制:
master只保证slaves中的一个操作成功，就返回，其他slave不管。 这个功能，是由google为MySQL引入的。

2.数据库主从复制分析的 7 个问题?
问题1：master的写操作，slaves被动的进行一样的操作，保持数据一致性，那么slave是否可以主动的进行写操作？
假设slave可以主动的进行写操作，slave又无法通知master，这样就导致了master和slave数据不一致了。因此slave不应该进行写操作，至少是slave上涉及到复制的数据库不可以写。实际上，这里已经揭示了读写分离的概念。

问题2：主从复制中，可以有N个slave,可是这些slave又不能进行写操作，要他们干嘛？
实现数据备份:
类似于高可用的功能，一旦master挂了，可以让slave顶上去，同时slave提升为master。

异地容灾:比如master在北京，地震挂了，那么在上海的slave还可以继续。
主要用于实现scale out,分担负载,可以将读的任务分散到slaves上。
(很可能的情况是，一个系统的读操作远远多于写操作，因此写操作发向master，读操作发向slaves进行操作)

问题3：主从复制中有master,slave1,slave2,...等等这么多MySQL数据库，那比如一个JAVA WEB应用到底应该连接哪个数据库?
我们在应用程序中可以这样，insert/delete/update这些更新数据库的操作，用connection(for master)进行操作，
select用connection(for slaves)进行操作。那我们的应用程序还要完成怎么从slaves选择一个来执行select，例如使用简单的轮循算法。
这样的话，相当于应用程序完成了SQL语句的路由，而且与MySQL的主从复制架构非常关联，一旦master挂了，某些slave挂了，那么应用程序就要修改了。能不能让应用程序与MySQL的主从复制架构没有什么太多关系呢？
找一个组件，application program只需要与它打交道，用它来完成MySQL的代理，实现SQL语句的路由。
MySQL proxy并不负责，怎么从众多的slaves挑一个？可以交给另一个组件(比如haproxy)来完成。
这就是所谓的MySQL READ WRITE SPLITE，MySQL的读写分离。

问题4：如果MySQL proxy , direct , master他们中的某些挂了怎么办？
总统一般都会弄个副总统，以防不测。同样的，可以给这些关键的节点来个备份。

问题5：当master的二进制日志每产生一个事件，都需要发往slave，如果我们有N个slave,那是发N次，还是只发一次？如果只发一次，发给了slave-1，那slave-2,slave-3,...它们怎么办？
显然，应该发N次。实际上，在MySQL master内部，维护N个线程，每一个线程负责将二进制日志文件发往对应的slave。master既要负责写操作，
还得维护N个线程，负担会很重。可以这样，slave-1是master的从，slave-1又是slave-2,slave-3,...的主，同时slave-1不再负责select。 slave-1将master的复制线程的负担，转移到自己的身上。这就是所谓的多级复制的概念。

问题6：当一个select发往MySQL proxy，可能这次由slave-2响应，下次由slave-3响应，这样的话，就无法利用查询缓存了。
应该找一个共享式的缓存，比如memcache来解决。将slave-2,slave-3,...这些查询的结果都缓存至mamcache中。

问题7：随着应用的日益增长，读操作很多，我们可以扩展slave，但是如果master满足不了写操作了，怎么办呢？
scale on ?更好的服务器？ 没有最好的，只有更好的，太贵了...
scale out ? 主从复制架构已经满足不了。
可以分库(垂直拆分)：表多，把关系紧密（比如同一模块）的表切分出来放在一个server上
分表(水平拆分)：表的数据多，把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上，

3.mysql 高并发环境解决方案?
MySQL 高并发环境解决方案： 分库 分表 分布式 增加二级缓存...
需求分析：互联网单位 每天大量数据读取，写入，并发性高。
现有解决方式：水平分库分表，由单点分布到多点数据库中，从而降低单点数据库压力。
集群方案：解决DB宕机带来的单点DB不能访问问题。
读写分离策略：极大限度提高了应用中Read数据的速度和并发量。无法解决高写入压力。

4.数据库崩溃时事务的恢复机制（REDO日志和UNDO日志）?
MySQL REDO日志和UNDO日志
Undo Log:
Undo Log是为了实现事务的原子性，在MySQL数据库InnoDB存储引擎中，还用了Undo Log来实现多版本并发控制(MVCC)。
事务的原子性(Atomicity)事务中的所有操作，要么全部完成，要么不做任何操作，不能只做部分操作。如果在执行的过程中发生了错误，要回滚(Rollback)到事务开始前的状态，就像这个事务从来没有执行过。
原理Undo Log的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。
然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。

之所以能同时保证原子性和持久化，是因为以下特点：
更新数据前记录Undo log。
为了保证持久性，必须将数据在事务提交前写到磁盘。只要事务成功提交，数据必然已经持久化。
Undo log必须先于数据持久化到磁盘。如果在G,H之间系统崩溃，undo log是完整的， 可以用来回滚事务。
如果在A-F之间系统崩溃,因为数据没有持久化到磁盘。所以磁盘上的数据还是保持在事务开始前的状态。

缺陷：每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能很低。
如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即Redo Log。

Redo Log:
原理和Undo Log相反，Redo Log记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。
当系统崩溃时，虽然数据没有持久化，但是Redo Log已经持久化。系统可以根据Redo Log的内容，将所有数据恢复到最新的状态。